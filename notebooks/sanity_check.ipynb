{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Sanity checks\n",
            "\n",
            "Here we will perform a bunch of sanity checks on the model to see if its working as desired or not."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Checking optimal log-likelihoods per permutation\n",
            "\n",
            "For the end-to-end model of learning both causal ordering as well as the model parameters to work, different permutations should produce different log-likelihoods with the optimal permutation producing the best likelihood possible."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "%load_ext autoreload"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "%autoreload 2\n",
            "import sys\n",
            "sys.path.append('..')\n",
            "\n",
            "\n",
            "# setup data\n",
            "from ocd.data import CausalDataModule\n",
            "import dycode\n",
            "import torch\n",
            "\n",
            "# setup model\n",
            "import lightning\n",
            "import lightning.pytorch.callbacks\n",
            "from ocd.training import OrderedTrainingModule\n",
            "\n",
            "\n",
            "dm = CausalDataModule(\n",
            "    name=\"asia\",  # small dataset asia\n",
            "    observation_size=4096,  # number of observation samples\n",
            "    intervention_size=256,  # set to 0 for no intervention\n",
            "    batch_size=64,\n",
            "    num_workers=0,  # set to 0 for no multiprocessing\n",
            "    val_size=0,  # 10% of data for validation, or use int for exact number of samples, set to 0 for no validation\n",
            "    pin_memory=True,  # set to True for faster data transfer to GPU (if available)\n",
            ")\n",
            "dm.setup(\"fit\")\n",
            "\n",
            "\n",
            "# Extract the category sizes\n",
            "in_features = dm.train_data[0].features_values\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Setup a fixed permutation below and train the model. You can use the following options:\n",
            "* `whole`: This will simply run the algorithm.\n",
            "* `correct_order`: This will do a topological sort on the correct DAG and feed that to the model. We hope to gain the best likelihood using this.\n",
            "* `seed`: This will be an integer value used to perform"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "permutations being used:\n",
                  "\n",
                  "[0, 4, 7, 5, 1, 6, 3, 2] backward score: 0.25\n",
                  "[1, 0, 2, 5, 3, 4, 6, 7] backward score: 0.5\n",
                  "[6, 7, 5, 3, 4, 0, 1, 2] backward score: 0.375\n",
                  "[6, 0, 4, 3, 7, 1, 5, 2] backward score: 0.375\n",
                  "[2, 5, 3, 1, 0, 6, 4, 7] backward score: 0.5\n",
                  "[5, 4, 1, 0, 6, 3, 2, 7] backward score: 0.0\n"
               ]
            }
         ],
         "source": [
            "import random\n",
            "from ocd.utils import topological_sort\n",
            "from ocd.evaluation import backward_score\n",
            "\n",
            "# Set to false if you want a quick run using the whole model\n",
            "prompt = True\n",
            "\n",
            "# Set the permutation to be used, use the seed to switch between permutations\n",
            "\n",
            "prompt_text = \"[LIST OF INTEGERS] create a set of random permutations that is fixed and obtained from the input seeds. (camma seperated)\\n\"\n",
            "prompt_text += \"When you enter seed=0 it will produce the correct ordering\\n\"\n",
            "prompt_text += \"Enter option: \"\n",
            "resp = 'whole' if not prompt else input(prompt_text)\n",
            "\n",
            "# perform trimming on a string x to remove all spaces\n",
            "seeds = [int(x.replace(' ', '')) for x in resp.split(',')]\n",
            "print(\"permutations being used:\\n\")\n",
            "FIXED_PERMUTATION = {}\n",
            "for seed in seeds:\n",
            "    if seed == 0:\n",
            "        perm = topological_sort(dm.datasets[0].dag)\n",
            "    else:\n",
            "        random.seed(seed)\n",
            "        perm = list(range(len(in_features)))\n",
            "        random.shuffle(perm)\n",
            "    score = backward_score(perm, dm.datasets[0].dag)\n",
            "    FIXED_PERMUTATION[f'seed_{seed}' if seed else 'correct'] = [perm,score]\n",
            "    print(perm, \"backward score:\", score)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "GPU available: False, used: False\n",
                  "TPU available: False, using: 0 TPU cores\n",
                  "IPU available: False, using: 0 IPUs\n",
                  "HPU available: False, using: 0 HPUs\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Running experiment with permutation [[0, 4, 7, 5, 1, 6, 3, 2], 0.25]\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n",
                  "  | Name  | Type                   | Params\n",
                  "-------------------------------------------------\n",
                  "0 | model | SinkhornOrderDiscovery | 677 K \n",
                  "-------------------------------------------------\n",
                  "677 K     Trainable params\n",
                  "0         Non-trainable params\n",
                  "677 K     Total params\n",
                  "2.711     Total estimated model params size (MB)\n"
               ]
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "f2cbfd5c44aa468da7788c2f01c42168",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Sanity Checking: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "b99eb2fa00034ab2a5714d520f5bfe30",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Training: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "`Trainer.fit` stopped: `max_epochs=43` reached.\n",
                  "GPU available: False, used: False\n",
                  "TPU available: False, using: 0 TPU cores\n",
                  "IPU available: False, using: 0 IPUs\n",
                  "HPU available: False, using: 0 HPUs\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Finished training on [[0, 4, 7, 5, 1, 6, 3, 2], 0.25] with loss: 4.6111249923706055\n",
                  "Running experiment with permutation [[1, 0, 2, 5, 3, 4, 6, 7], 0.5]\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n",
                  "  | Name  | Type                   | Params\n",
                  "-------------------------------------------------\n",
                  "0 | model | SinkhornOrderDiscovery | 677 K \n",
                  "-------------------------------------------------\n",
                  "677 K     Trainable params\n",
                  "0         Non-trainable params\n",
                  "677 K     Total params\n",
                  "2.711     Total estimated model params size (MB)\n"
               ]
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "6012e3d7e1c44a8cbdaa0ca630f3073c",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Sanity Checking: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "0abafe53438a4c5da974eaef08b95600",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Training: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "`Trainer.fit` stopped: `max_epochs=43` reached.\n",
                  "GPU available: False, used: False\n",
                  "TPU available: False, using: 0 TPU cores\n",
                  "IPU available: False, using: 0 IPUs\n",
                  "HPU available: False, using: 0 HPUs\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Finished training on [[1, 0, 2, 5, 3, 4, 6, 7], 0.5] with loss: 4.6557512283325195\n",
                  "Running experiment with permutation [[6, 7, 5, 3, 4, 0, 1, 2], 0.375]\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n",
                  "  | Name  | Type                   | Params\n",
                  "-------------------------------------------------\n",
                  "0 | model | SinkhornOrderDiscovery | 677 K \n",
                  "-------------------------------------------------\n",
                  "677 K     Trainable params\n",
                  "0         Non-trainable params\n",
                  "677 K     Total params\n",
                  "2.711     Total estimated model params size (MB)\n"
               ]
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "ee60c50190ee41aeba624a45b862989c",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Sanity Checking: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "21b456964929404e8d2b9b6981f17c82",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Training: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "`Trainer.fit` stopped: `max_epochs=43` reached.\n",
                  "GPU available: False, used: False\n",
                  "TPU available: False, using: 0 TPU cores\n",
                  "IPU available: False, using: 0 IPUs\n",
                  "HPU available: False, using: 0 HPUs\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Finished training on [[6, 7, 5, 3, 4, 0, 1, 2], 0.375] with loss: 4.504185676574707\n",
                  "Running experiment with permutation [[6, 0, 4, 3, 7, 1, 5, 2], 0.375]\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n",
                  "  | Name  | Type                   | Params\n",
                  "-------------------------------------------------\n",
                  "0 | model | SinkhornOrderDiscovery | 677 K \n",
                  "-------------------------------------------------\n",
                  "677 K     Trainable params\n",
                  "0         Non-trainable params\n",
                  "677 K     Total params\n",
                  "2.711     Total estimated model params size (MB)\n"
               ]
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "8413ddfd53564a3098a8ec481d6279b2",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Sanity Checking: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "f5c1533509604e0bb270adac3634a122",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Training: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "`Trainer.fit` stopped: `max_epochs=43` reached.\n",
                  "GPU available: False, used: False\n",
                  "TPU available: False, using: 0 TPU cores\n",
                  "IPU available: False, using: 0 IPUs\n",
                  "HPU available: False, using: 0 HPUs\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Finished training on [[6, 0, 4, 3, 7, 1, 5, 2], 0.375] with loss: 4.657809734344482\n",
                  "Running experiment with permutation [[2, 5, 3, 1, 0, 6, 4, 7], 0.5]\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n",
                  "  | Name  | Type                   | Params\n",
                  "-------------------------------------------------\n",
                  "0 | model | SinkhornOrderDiscovery | 677 K \n",
                  "-------------------------------------------------\n",
                  "677 K     Trainable params\n",
                  "0         Non-trainable params\n",
                  "677 K     Total params\n",
                  "2.711     Total estimated model params size (MB)\n"
               ]
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "3c2ff3cbb6944da5aa2ee3853ab00aa7",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Sanity Checking: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "61dc9f7c64db481bbdfca2185221a7ef",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Training: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "`Trainer.fit` stopped: `max_epochs=43` reached.\n",
                  "GPU available: False, used: False\n",
                  "TPU available: False, using: 0 TPU cores\n",
                  "IPU available: False, using: 0 IPUs\n",
                  "HPU available: False, using: 0 HPUs\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Finished training on [[2, 5, 3, 1, 0, 6, 4, 7], 0.5] with loss: 4.531513214111328\n",
                  "Running experiment with permutation [[5, 4, 1, 0, 6, 3, 2, 7], 0.0]\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n",
                  "  | Name  | Type                   | Params\n",
                  "-------------------------------------------------\n",
                  "0 | model | SinkhornOrderDiscovery | 677 K \n",
                  "-------------------------------------------------\n",
                  "677 K     Trainable params\n",
                  "0         Non-trainable params\n",
                  "677 K     Total params\n",
                  "2.711     Total estimated model params size (MB)\n"
               ]
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "f9d44ee237a246b4ac13a846ffd3e5c3",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Sanity Checking: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "9253c5d05acb4c619beafefcd563c8c2",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Training: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "`Trainer.fit` stopped: `max_epochs=43` reached.\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Finished training on [[5, 4, 1, 0, 6, 3, 2, 7], 0.0] with loss: 4.327533721923828\n"
               ]
            }
         ],
         "source": [
            "\n",
            "from lightning.pytorch import loggers as pl_loggers\n",
            "dycode.register_context(torch)\n",
            "# iterate over all the key item pairs in the dictionary FIXED_PERMUTATION\n",
            "for VERSION, permutation in FIXED_PERMUTATION.items():\n",
            "    print(f\"Running experiment with permutation {permutation}\")\n",
            "    \n",
            "\n",
            "    logger = pl_loggers.tensorboard.TensorBoardLogger(\"lightning_logs\", name=\"sanity_check\", version=VERSION)\n",
            "\n",
            "    # set callbacks for the trainer\n",
            "    callbacks = [\n",
            "        # monitor the learning rate (log to tensorboard)\n",
            "        lightning.pytorch.callbacks.LearningRateMonitor(logging_interval=\"epoch\"),\n",
            "    ]\n",
            "\n",
            "    trainer = lightning.Trainer(\n",
            "        # accelerator=\"mps\",  # remove this line to run on CPU\n",
            "        callbacks=callbacks,\n",
            "        # precision=16, # for mixed precision training\n",
            "        # gradient_clip_val=1.0,\n",
            "        # gradient_clip_algorithm=\"value\",\n",
            "        max_epochs=43,\n",
            "        track_grad_norm=\"inf\",\n",
            "        log_every_n_steps=1,\n",
            "        logger=logger,\n",
            "        # overfit_batches=3,\n",
            "        # detect_anomaly=True,\n",
            "    )\n",
            "\n",
            "    # Extract the category sizes\n",
            "    in_features = dm.train_data[0].features_values\n",
            "\n",
            "\n",
            "    # torch.autograd.set_detect_anomaly(True)\n",
            "    tm = OrderedTrainingModule(\n",
            "        in_covariate_features=in_features,\n",
            "        hidden_features_per_covariate=[\n",
            "            [128 for i in range(len(in_features))],\n",
            "            [64 for i in range(len(in_features))],\n",
            "            [32 for i in range(len(in_features))],\n",
            "        ],\n",
            "        gamma_scaling=1,\n",
            "        fixed_permutation=permutation[0],\n",
            "        log_permutation=False,\n",
            "        batch_norm=False,\n",
            "        criterion_args= dict(\n",
            "            terms=[\n",
            "                \"ocd.training.terms.OrderedLikelihoodTerm\",\n",
            "                # \"ocd.training.terms.PermanentMatrixPenalizer\",\n",
            "                dict(\n",
            "                    name=\"norm(gamma)\",\n",
            "                    term_function='lambda training_module: training_module.model.Gamma.norm(float(\"inf\"))',\n",
            "                    factor=0,\n",
            "                ),\n",
            "                dict(\n",
            "                    name=\"norm(layers)\",\n",
            "                    term_function='lambda training_module: max([layer.linear.weight.norm(float(\"inf\")) for layer in training_module.model.made.layers])',\n",
            "                    factor=0,\n",
            "                ),\n",
            "            ],\n",
            "            regularizations=[\n",
            "                    dict(\n",
            "                        name=\"nothing\",\n",
            "                        term_function=\"lambda batch: torch.zeros(1, device=batch[0].device)\",\n",
            "                        factor=\"def factor(training_module, results_dict):\\n\\ttraining_module.loss = results_dict['loss']\\n\\treturn 0\",\n",
            "                    ),\n",
            "            ],\n",
            "        ),\n",
            "        noise_factor=0,\n",
            "        optimizer=['torch.optim.Adam', 'torch.optim.Adam'],\n",
            "        optimizer_parameters=['model.made', 'model.Gamma'],\n",
            "        optimizer_args=[\n",
            "            dict(\n",
            "                weight_decay=0.0001,\n",
            "            ),\n",
            "            dict()\n",
            "        ],\n",
            "        optimizer_is_active=[\n",
            "            'lambda training_module: training_module.current_epoch % 10 < 10',\n",
            "            'lambda training_module: training_module.current_epoch % 10 < 10',\n",
            "        ],\n",
            "        tau_scheduler=\"lambda training_module: max(0.0001, 0.5 * 0.99 ** (training_module.current_epoch // 1000))\",\n",
            "        n_sinkhorn_scheduler=\"lambda training_module: min(120, max(60, 60 + ((training_module.current_epoch - 60) // 10)))\",\n",
            "        lr=0.001,\n",
            "        scheduler=\"torch.optim.lr_scheduler.ExponentialLR\",\n",
            "        scheduler_interval=\"epoch\",\n",
            "        scheduler_args={\"gamma\": 0.999},\n",
            "    )\n",
            "    try:\n",
            "        trainer.fit(tm, dm)\n",
            "    except KeyboardInterrupt:\n",
            "        print(\"Keyboard interrupt detected, stopping training\")\n",
            "    print(f\"Finished training on {permutation} with loss: {tm.loss}\")\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "causal",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.15 (main, Oct 11 2022, 21:39:54) \n[Clang 14.0.0 (clang-1400.0.29.102)]"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "5a2f498358c3663e2e3193e62762a23cd9e21c3899e1ed9b7a4dc1ddd6985d97"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}