activation: torch.nn.ReLU
activation_args: null
batch_norm: false
batch_norm_args: null
batch_transform: null
bias: false
criterion: lightning_toolbox.Criterion
criterion_args:
  terms:
  - ocd.training.terms.OrderedLikelihoodTerm
  - ocd.training.terms.PermanentMatrixPenalizer
  - factor: 0
    name: norm(gamma)
    term_function: 'lambda training_module: training_module.model.Gamma.norm(float("inf"))'
  - factor: 0
    name: norm(layers)
    term_function: 'lambda training_module: max([layer.linear.weight.norm(float("inf"))
      for layer in training_module.model.made.layers])'
embedding_dim: 0
embedding_normalization: null
embedding_normalization_eps: 0
fixed_permutation: null
hidden_features_per_covariate: &id001
- - 128
  - 128
  - 128
  - 128
  - 128
  - 128
  - 128
  - 128
- - 64
  - 64
  - 64
  - 64
  - 64
  - 64
  - 64
  - 64
- - 32
  - 32
  - 32
  - 32
  - 32
  - 32
  - 32
  - 32
in_covariate_features: &id002
- 2
- 2
- 2
- 2
- 2
- 2
- 2
- 2
initialize_superclass: true
log_permutation: true
log_permutation_freq: 5
lr: 0.001
model_args:
  activation: torch.nn.ReLU
  activation_args: null
  batch_norm: false
  batch_norm_args: null
  bias: false
  hidden_features_per_covariate: *id001
  in_covariate_features: *id002
  n_iter: 10
  tau: 0.1
model_cls: ocd.models.order_discovery.SinkhornOrderDiscovery
n_sinkhorn_iterations: 10
n_sinkhorn_scheduler: 'lambda training_module: min(60, max(20, 20 + ((training_module.current_epoch
  - 20) // 10)))'
optimizer:
- torch.optim.Adam
- torch.optim.Adam
optimizer_args:
- weight_decay: 0.0001
- {}
optimizer_is_active:
- 'lambda training_module: training_module.current_epoch % 10 < 10'
- 'lambda training_module: training_module.current_epoch % 10 < 10'
optimizer_parameters:
- model.made
- model.Gamma
save_hparams: true
scheduler: torch.optim.lr_scheduler.ExponentialLR
scheduler_args:
  gamma: 0.999
scheduler_frequency: 1
scheduler_interval: epoch
scheduler_monitor: null
scheduler_name: null
scheduler_optimizer: null
tau: 0.1
tau_scheduler: 'lambda training_module: max(0.003, 0.5 * 0.8 ** (training_module.current_epoch
  // 1))'
