{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent directory to path (to use ocd package)\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# set PYTORCH_ENABLE_MPS_FALLBACK=1 in current environment to enable MPS fallback\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "# import packages\n",
    "import torch\n",
    "import lightning\n",
    "import lightning.pytorch.callbacks\n",
    "from ocd.training import OrderedTrainingModule\n",
    "from ocd.training.terms import OrderedLikelihoodTerm, PermanentMatrixPenalizer\n",
    "from ocd.data import CausalDataModule # for loading data\n",
    "import dycode # for dynamic code execution\n",
    "import torch\n",
    "\n",
    "# register torch in dynamic code context\n",
    "dycode.register_context(torch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callbacks for the trainer\n",
    "callbacks = [\n",
    "    # monitor the learning rate (log to tensorboard)\n",
    "    lightning.pytorch.callbacks.LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "]\n",
    "\n",
    "trainer = lightning.Trainer(\n",
    "    # accelerator=\"mps\",  # remove this line to run on CPU\n",
    "    callbacks=callbacks,\n",
    "    # precision=16, # for mixed precision training\n",
    "    # gradient_clip_val=1.0,\n",
    "    # gradient_clip_algorithm=\"value\",\n",
    "    track_grad_norm=\"inf\",\n",
    "    log_every_n_steps=1,\n",
    "    # detect_anomaly=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data \n",
    "dm = CausalDataModule(\n",
    "    name=\"https://www.bnlearn.com/bnrepository/survey/survey.bif.gz\", \n",
    "    observation_size=2048,  # number of observation samples\n",
    "    intervention_size=256,  # set to 0 for no intervention\n",
    "    batch_size=128,\n",
    "    num_workers=0,  # set to 0 for no multiprocessing\n",
    "    val_size=0,  # 10% of data for validation, or use int for exact number of samples, set to 0 for no validation\n",
    "    pin_memory=True,  # set to True for faster data transfer to GPU (if available)\n",
    ")\n",
    "\n",
    "# read general stats of the data to setup the model later\n",
    "dm.setup(\"fit\") # prepare the data to read general stats (e.g. number of features and nodes)\n",
    "in_features = dm.train_data[0].features_values # number of features (used for setting the input size of the model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model and training parameters\n",
    "tm = OrderedTrainingModule(\n",
    "    # input parameters\n",
    "    in_covariate_features=in_features,  # number of nodes and features in the data\n",
    "    # network architecture\n",
    "    hidden_features_per_covariate=[\n",
    "        [32 for i in range(len(in_features))],\n",
    "        [16 for i in range(len(in_features))],\n",
    "        [8 for i in range(len(in_features))],\n",
    "    ],\n",
    "    batch_norm=False,\n",
    "    # training objective\n",
    "    criterion_args=dict(\n",
    "        terms=[\n",
    "            \"ocd.training.terms.OrderedLikelihoodTerm\",\n",
    "            # PermanentMatrixPenalizer(factor=1),\n",
    "        ],\n",
    "        # regularizations=[\n",
    "        #     dict(\n",
    "        #         name=\"nothing\",\n",
    "        #         term_function=\"lambda batch: torch.zeros(1, device=batch[0].device)\",\n",
    "        #         factor=\"def factor(training_module, results_dict):\\n\\ttraining_module.loss = results_dict['loss']\\n\\treturn 0\",\n",
    "        #     )\n",
    "        # ],\n",
    "    ),\n",
    "    # training parameters\n",
    "    optimizer=['torch.optim.AdamW', 'torch.optim.SGD'],\n",
    "    optimizer_parameters=['model.made', 'model._gamma'],\n",
    "    optimizer_is_active=[\n",
    "        'lambda training_module: True',\n",
    "        'lambda training_module: True',\n",
    "    ],\n",
    "    tau_scheduler=\"lambda training_module: max(0.0005, 0.01 * 0.5 ** (training_module.current_epoch // 5))\",\n",
    "    # tau_scheduler=\"lambda training_module: 0.001\",\n",
    "    # n_sinkhorn_scheduler=\"lambda training_module: min(60, max(20, 20 + ((training_module.current_epoch - 20) // 10)))\",\n",
    "    n_sinkhorn_scheduler=\"lambda training_module: 20\",\n",
    "    lr=[0.001, 1],\n",
    "    scheduler=\"torch.optim.lr_scheduler.ExponentialLR\",\n",
    "    scheduler_interval=\"epoch\",\n",
    "    scheduler_args={\"gamma\": 0.999},\n",
    "    # log\n",
    "    # log_permutation=True,\n",
    "    # log_permutation_freq=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "trainer.fit(tm, dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune the learned ordering to obtain a DAG\n",
    "from ocd.post_processing.pruning import prune, PruningMethod\n",
    "from ocd.evaluation import shd\n",
    "import numpy as np\n",
    "\n",
    "ground_truth = dm.datasets[0].dag  # ground truth DAG\n",
    "\n",
    "pruned_dag = prune(\n",
    "    ordering=tm.get_ordering(),\n",
    "    data=dm.datasets[0].samples,\n",
    "    method=PruningMethod.CONDITIONAL_INDEPENDENCE_TESTING,\n",
    "    verbose=1,\n",
    "    method_params=dict(threshold=0.05),\n",
    ")\n",
    "\n",
    "print(\"The number of edges in the original DAG is:\", np.sum(ground_truth).astype(int))\n",
    "print(\"Structural hamming distance between pruned_dag and original_dag is:\", shd(pruned_dag, ground_truth))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further prune using interventional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocd.models.utils import log_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = dm.datasets[0].dag\n",
    "count_incorrect = 0\n",
    "# get the interventional dataframes with the values of the intervention\n",
    "for intervention_eposide in dm.datasets[1:]:\n",
    "    intervention_node_name = intervention_eposide.intervention_node\n",
    "    # check the index of the intervention node in intervention_eposide.samples.columns\n",
    "    gt_intervention_node_index = intervention_eposide.samples.columns.get_loc(intervention_node_name)\n",
    "    # find the node being intervened on (it should have the lowest log_prob in the episode)\n",
    "    dataloader = torch.utils.data.DataLoader(intervention_eposide, batch_size=32, shuffle=False)\n",
    "    log_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(tm.device)\n",
    "            processed_batch = tm.process_batch(batch).to(tm.device)\n",
    "            logits = tm.model(processed_batch)\n",
    "            log_probs.append(log_prob(logits, in_features, batch, reduce=False))\n",
    "\n",
    "    intervention_node_index = torch.cat(log_probs).mean(0).argmin().item()\n",
    "    count_incorrect = count_incorrect + (intervention_node_index != gt_intervention_node_index)\n",
    "    pruned_dag = prune(\n",
    "        ordering=tm.get_ordering(),\n",
    "        data=intervention_eposide.samples,\n",
    "        method=PruningMethod.CONDITIONAL_INDEPENDENCE_TESTING,\n",
    "        dag=pruned_dag,\n",
    "        interventional_column=intervention_node_index,\n",
    "        verbose=1,\n",
    "        method_params={\n",
    "            \"threshold\": 0.05,\n",
    "        },\n",
    "    )\n",
    "\n",
    "print('wrong', count_incorrect)\n",
    "print(\"The number of edges in the original DAG is: \", np.sum(ground_truth).astype(int))\n",
    "print(\"Structural hamming distance between pruned_dag and original_dag is: \", shd(pruned_dag, ground_truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a2f498358c3663e2e3193e62762a23cd9e21c3899e1ed9b7a4dc1ddd6985d97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
