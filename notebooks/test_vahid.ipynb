{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning\n",
    "import lightning.pytorch.callbacks\n",
    "from ocd.training import OrderedTrainingModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callbacks for the trainer\n",
    "callbacks = [\n",
    "    # monitor the learning rate (log to tensorboard)\n",
    "    lightning.pytorch.callbacks.LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "]\n",
    "\n",
    "trainer = lightning.Trainer(\n",
    "    # accelerator=\"mps\",  # remove this line to run on CPU\n",
    "    callbacks=callbacks,\n",
    "    # precision=16, # for mixed precision training\n",
    "    gradient_clip_val=1.0,\n",
    "    gradient_clip_algorithm=\"value\",\n",
    "    track_grad_norm=\"inf\",\n",
    "    log_every_n_steps=1,\n",
    "    # detect_anomaly=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data\n",
    "from ocd.data import CausalDataModule\n",
    "import dycode\n",
    "import torch\n",
    "\n",
    "dycode.register_context(torch)\n",
    "\n",
    "dm = CausalDataModule(\n",
    "    name=\"alarm\",  # small dataset asia\n",
    "    observation_size=2048,  # number of observation samples\n",
    "    intervention_size=256,  # set to 0 for no intervention\n",
    "    batch_size=128,\n",
    "    num_workers=0,  # set to 0 for no multiprocessing\n",
    "    val_size=0,  # 10% of data for validation, or use int for exact number of samples, set to 0 for no validation\n",
    "    pin_memory=True,  # set to True for faster data transfer to GPU (if available)\n",
    ")\n",
    "dm.setup(\"fit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over data and find the unique values for each covariate\n",
    "# each dataset has a samples attribute which is a pandas dataframe\n",
    "# concatenate all the samples together\n",
    "import pandas as pd\n",
    "\n",
    "samples = pd.concat([dataset.samples for dataset in dm.datasets])\n",
    "# find the unique values for each covariate\n",
    "unique_values_count = samples.nunique()\n",
    "# find the the possible values for each covariate\n",
    "unique_values = samples.apply(lambda x: x.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_features = dm.train_data[0].dataset.features_values\n",
    "# if val_size = 0, then use the following line instead of the above line\n",
    "# in_features = dm.train_data[0].features_values\n",
    "in_features = unique_values_count.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set torch.anomaly_detection(True) to debug\n",
    "import torch\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "tm = OrderedTrainingModule(\n",
    "    in_covariate_features=in_features,\n",
    "    hidden_features_per_covariate=[\n",
    "        [128 for i in range(len(in_features))],\n",
    "        [64 for i in range(len(in_features))],\n",
    "        [32 for i in range(len(in_features))],\n",
    "    ],\n",
    "    batch_norm=False,\n",
    "    criterion_args=dict(\n",
    "        terms=[\n",
    "            \"ocd.training.terms.OrderedLikelihoodTerm\",\n",
    "            dict(\n",
    "                name=\"norm(gamma)\",\n",
    "                term_function='lambda training_module: training_module.model.Gamma.norm(float(\"inf\"))',\n",
    "                factor=0,\n",
    "            ),\n",
    "            # dict(\n",
    "            #     name='nothing',\n",
    "            #     term_function='def term(training_module, batch):\\n\\ttraining_module.batch=batch\\n\\treturn torch.zeros(1, device=batch.device)',\n",
    "            #     factor=0,\n",
    "            # )\n",
    "        ]\n",
    "    ),\n",
    "    optimizer=\"torch.optim.AdamW\",\n",
    "    tau_scheduler=\"lambda training_module: 1 * (0.98 ** training_module.current_epoch if training_module.current_epoch < 1000 else 0.01)\",\n",
    "    lr=0.001,\n",
    "    scheduler=\"torch.optim.lr_scheduler.ExponentialLR\",\n",
    "    scheduler_interval=\"epoch\",\n",
    "    scheduler_args={\"gamma\": 0.99},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(tm, dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.temp_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tm.batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undo one-hot encoding\n",
    "original_batch = torch.argmax(batch.reshape(batch.shape[0], -1, 2), dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = tm.to(\"cpu\")\n",
    "loss = tm.criterion(batch=batch.to(\"cpu\"), original_batch=original_batch.to(\"cpu\"), training_module=tm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.model.made(batch.to(\"cpu\"), tm.model.Gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocd.models.sinkhorn import sinkhorn\n",
    "\n",
    "tm.model.made(batch.to(\"cpu\"), sinkhorn(tm.model.Gamma, 0.01, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, p = OrderedLinear.forward(tm.model.made.density_estimator, *tm.model.made.layers((batch.to(\"cpu\"), P)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.exp().isnan().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocd.models.layers.ordered_linear import OrderedLinear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = sinkhorn(tm.model.Gamma, 0.01, 100).argmax(-1)\n",
    "\n",
    "# create a permuation matrix for the order\n",
    "P = torch.zeros_like(tm.model.Gamma)\n",
    "P[torch.arange(P.shape[0]), order] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tm.parameters():\n",
    "    # check if there is any nan\n",
    "    if torch.isnan(param).any():\n",
    "        print(param)\n",
    "    # check if there is any inf\n",
    "    if torch.isinf(param).any():\n",
    "        print(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shit = sinkhorn(tm.model.Gamma, 0.1, 100)\n",
    "shit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsums = torch.cumsum(torch.cat([torch.zeros(1), torch.arange(1, 11)], dim=0), dim=0).int()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_features = torch.arange(1, 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.norm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.arange(1, 56).reshape(1, -1).float()\n",
    "\n",
    "# [ mat[:, cumsums[i] : cumsums[i + 1]] for i in range(len(cov_features)) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[:, cumsums[9] : cumsums[10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the max l-inf norm of the matrix\n",
    "mat.norm(float(\"inf\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52095eaac6f7430dcd770b4bb1719550039f99e3c10e23775974db5ba0b67989"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
