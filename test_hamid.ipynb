{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import typing as th\n",
    "import os\n",
    "\n",
    "#count the number of cpu workers\n",
    "num_workers = os.cpu_count()\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "perm must be a permutation of [0, 1, ..., n-1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/hamidreza/Work/myprojects/ocd/test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hamidreza/Work/myprojects/ocd/test.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m perm \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hamidreza/Work/myprojects/ocd/test.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(perm)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hamidreza/Work/myprojects/ocd/test.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mset\u001b[39m(perm) \u001b[39m==\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mrange\u001b[39m(n)), \u001b[39m\"\u001b[39m\u001b[39mperm must be a permutation of [0, 1, ..., n-1]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hamidreza/Work/myprojects/ocd/test.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m9\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hamidreza/Work/myprojects/ocd/test.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m P \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((n, n))\n",
      "\u001b[0;31mAssertionError\u001b[0m: perm must be a permutation of [0, 1, ..., n-1]"
     ]
    }
   ],
   "source": [
    "# Create a permutation tensor from a permutation list\n",
    "import torch\n",
    "\n",
    "perm = [0, 2, 2]\n",
    "\n",
    "n = len(perm)\n",
    "assert set(perm) == set(range(n)), \"perm must be a permutation of [0, 1, ..., n-1]\"\n",
    "\n",
    "inputs = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.float32)\n",
    "\n",
    "P = torch.zeros((n, n))\n",
    "P[torch.arange(n), perm] = 1\n",
    "perm = P \n",
    "P = P.to(inputs.device)\n",
    "P = P.type(inputs.dtype)\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_cov_features = [1, 2, 3]\n",
    "out_cov_features = [6, 4, 2]\n",
    "mask = torch.Tensor([[1, 0, 0],\n",
    "                     [0, 1, 1],\n",
    "                     [1, 1, 0]])\n",
    "mask = torch.repeat_interleave(mask, torch.tensor(in_cov_features), dim=1)\n",
    "mask = torch.repeat_interleave(mask, torch.tensor(out_cov_features), dim=0)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.9321, -0.2592, -1.1750,  0.6710],\n",
      "        [-2.6185,  0.9256,  1.5300,  0.6207],\n",
      "        [ 0.1632, -0.8190, -0.8127, -0.2467],\n",
      "        [-0.7536,  1.4659,  1.3000,  0.3614]], requires_grad=True)\n",
      "tensor([[8.2183e-16, 2.1139e-02, 9.9544e-01, 9.7635e-05],\n",
      "        [8.5280e-01, 2.7085e-12, 3.1882e-17, 2.8903e-09],\n",
      "        [6.7860e-09, 9.7886e-01, 4.5614e-03, 1.6206e-01],\n",
      "        [1.4720e-01, 2.6450e-07, 6.8929e-09, 8.3784e-01]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2954, 0.2970, 0.4077, 0.2531, 0.2448, 0.2509, 0.2511, 0.4572, 0.5428,\n",
       "         0.2179, 0.3579, 0.4242],\n",
       "        [0.2656, 0.4169, 0.3174, 0.2531, 0.2448, 0.2509, 0.2511, 0.6560, 0.3440,\n",
       "         0.3749, 0.2230, 0.4020],\n",
       "        [0.3578, 0.4234, 0.2188, 0.2531, 0.2448, 0.2509, 0.2511, 0.5409, 0.4591,\n",
       "         0.2425, 0.4613, 0.2962],\n",
       "        [0.3300, 0.2620, 0.4080, 0.2531, 0.2448, 0.2509, 0.2511, 0.4950, 0.5050,\n",
       "         0.2505, 0.3337, 0.4159],\n",
       "        [0.4299, 0.3299, 0.2403, 0.2531, 0.2448, 0.2509, 0.2511, 0.3295, 0.6705,\n",
       "         0.2711, 0.3667, 0.3622],\n",
       "        [0.2954, 0.2970, 0.4077, 0.2531, 0.2448, 0.2509, 0.2511, 0.4572, 0.5428,\n",
       "         0.2179, 0.3579, 0.4242],\n",
       "        [0.3309, 0.2963, 0.3728, 0.2531, 0.2448, 0.2509, 0.2511, 0.6132, 0.3868,\n",
       "         0.3949, 0.3698, 0.2352],\n",
       "        [0.3484, 0.3791, 0.2726, 0.2531, 0.2448, 0.2509, 0.2511, 0.6254, 0.3746,\n",
       "         0.2131, 0.4240, 0.3629],\n",
       "        [0.2885, 0.4528, 0.2587, 0.2531, 0.2448, 0.2509, 0.2511, 0.3842, 0.6158,\n",
       "         0.4002, 0.4505, 0.1493],\n",
       "        [0.2261, 0.2140, 0.5599, 0.2531, 0.2448, 0.2509, 0.2511, 0.6994, 0.3006,\n",
       "         0.7449, 0.1607, 0.0944]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from ocd.models.order_discovery import SinkhornOrderDiscovery\n",
    "import torch\n",
    "\n",
    "batch_size = 10\n",
    "cov_in = [3, 4, 2, 3]\n",
    "# generate a random one-hot vector of size k = 3\n",
    "x = torch.zeros(batch_size, sum(cov_in))\n",
    "cummul = 0\n",
    "for cat_sz in cov_in:\n",
    "    x[torch.arange(batch_size), cummul + torch.randint(0, cat_sz, (batch_size,))] = 1\n",
    "    cummul += cat_sz\n",
    "\n",
    "model = SinkhornOrderDiscovery(\n",
    "    in_covariate_features=cov_in,\n",
    "    hidden_features_per_covariate=[[10, 20, 30, 10],\n",
    "                                   [20, 30, 10, 5],\n",
    "                                   [40, 30, 10, 7]],\n",
    "    bias=True,\n",
    "    activation=torch.nn.ReLU,)\n",
    "\n",
    "model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "batch_size = 10\n",
    "cov_in = [3, 4, 2, 3]\n",
    "# generate a random one-hot vector of size k = 3\n",
    "x = torch.zeros(batch_size, sum(cov_in))\n",
    "cummul = 0\n",
    "for cat_sz in cov_in:\n",
    "    x[torch.arange(batch_size), cummul + torch.randint(0, cat_sz, (batch_size,))] = 1\n",
    "    cummul += cat_sz\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0458, 0.9956, 0.9586],\n",
      "        [1.0000, 1.0000, 1.0000],\n",
      "        [1.0002, 0.9521, 1.0476],\n",
      "        [0.9973, 0.9645, 1.0382],\n",
      "        [1.0404, 0.9332, 1.0264]])\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from ocd.models.sinkhorn import sample_permutation_matrix\n",
    "\n",
    "P = sample_permutation_matrix(torch.Tensor([[1, 0, 0],\n",
    "                                        [0, 1, 10], \n",
    "                                        [1, 1, 0]]),\n",
    "                                        n_samples=5, train=True, n_iter=10, tau=0.1)\n",
    "\n",
    "print(P.sum(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5829, 1.2029, 1.3771, 1.6821, 1.6871, 1.1648, 1.5599, 1.0990, 1.2029,\n",
       "        1.1375], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from ocd.models.made import SingleMaskedBlockMADE\n",
    "# from ocd.models.utils import log_prob\n",
    "from ocd.models.utils import log_prob\n",
    "\n",
    "model = SingleMaskedBlockMADE(\n",
    "    in_covariate_features=cov_in,\n",
    "    hidden_features_per_covariate=[[10, 20, 30, 10],\n",
    "                                   [20, 30, 10, 5],\n",
    "                                   [40, 30, 10, 7]],\n",
    "    bias=True,\n",
    "    activation=torch.nn.ReLU,\n",
    ")\n",
    "\n",
    "probas = model(x, perm=[0, 1, 2, 3])\n",
    "log_prob(probas, cov_in, categories=[[0, 2, 1, 2] for _ in range(x.shape[0])], reduce=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
