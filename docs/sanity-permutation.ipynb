{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# set PYTORCH_ENABLE_MPS_FALLBACK=1 in your environment\n",
    "\n",
    "import os \n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "import yaml\n",
    "import torch\n",
    "import lightning_toolbox as ltb\n",
    "import lightning\n",
    "import dypy as dy\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from ocd.models.permutation.utils import all_permutations\n",
    "# import sys\n",
    "# import ocd\n",
    "# import random\n",
    "device = 'cpu'\n",
    "# create a random permutation of n numbers\n",
    "\n",
    "data_config = yaml.safe_load(\n",
    "    open(\"../experiments/intervention/data/chain-3.yml\", \"r\")\n",
    ")\n",
    "model_config = yaml.safe_load(open(\"../experiments/intervention/model.yml\", \"r\"))\n",
    "\n",
    "n = data_config[\"init_args\"][\"dataset_args\"][\"scm_generator_args\"][\"graph_generator_args\"][\"n\"]\n",
    "model_config[\"init_args\"][\"model_args\"][\"in_features\"] = n\n",
    "\n",
    "# setup fixed perm\n",
    "enforce_perm = torch.randperm(n).tolist()\n",
    "data_config[\"init_args\"][\"dataset_args\"][\"scm_generator_args\"][\"graph_generator_args\"][\n",
    "    \"enforce_ordering\"\n",
    "] = enforce_perm\n",
    "model_config[\"init_args\"][\"model_args\"][\"ordering\"] = enforce_perm\n",
    "model_config[\"init_args\"][\"model_args\"][\"scale_transform_s_args\"] = dict(post_act_scale=5.0, normalization=None)\n",
    "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_args\"] = dict(\n",
    "    # num_hard_samples=100,\n",
    "    permutation_type=\"hybrid-sparse-map-simulator\",\n",
    "    # num_samples=20,\n",
    "    # buffer_replace_prob=0.5,\n",
    "    # buffer_replay_prob=0.5,\n",
    "    # buffer_size=200,\n",
    ")\n",
    "\n",
    "# trainer_config = yaml.safe_load(open(\"experiments/intervention/trainer.yml\", \"r\"))\n",
    "# trainer_config[\"max_epochs\"] = 400\n",
    "# trainer_config['accelerator'] = device\n",
    "# trainer_config[\"enable_progress_bar\"] = True\n",
    "# trainer_config[\"enable_model_summary\"] = True\n",
    "# grad_clip_val = 1000\n",
    "\n",
    "# dm = ltb.DataModule(**data_config[\"init_args\"])\n",
    "# model = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
    "# model = model.to(device)\n",
    "# trainer = lightning.Trainer(\n",
    "#     **trainer_config,\n",
    "#     callbacks=[lightning.pytorch.callbacks.LearningRateMonitor()],\n",
    "#     gradient_clip_val=1.0,\n",
    "#     gradient_clip_algorithm=\"value\",\n",
    "# )\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LearnablePermutation(num_features=3, permutation_type=hybrid-sparse-map-simulator),\n",
       " LegacyLearnablePermutation(num_features=3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightning import seed_everything\n",
    "\n",
    "args = dict(\n",
    "    # num_hard_samples=100,\n",
    "    permutation_type=\"hybrid-sparse-map-simulator\",\n",
    "    # permutation_type='soft'\n",
    ")\n",
    "batch_size = 50\n",
    "\n",
    "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_args\"] = args\n",
    "seed_everything(42)\n",
    "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_cls\"] = \"ocd.models.permutation.LearnablePermutation\"\n",
    "model_new = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
    "model_config[\"init_args\"][\"model_args\"][\n",
    "    \"permutation_learner_cls\"\n",
    "] = \"ocd.models.permutation.LegacyLearnablePermutation\"\n",
    "model_old = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
    "model_new.model.permutation_model.gamma = model_old.model.permutation_model.gamma\n",
    "model_new.model.permutation_model, model_old.model.permutation_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MaxBackward1>)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "new_results1 = model_new.model.permutation_model(batch_size)\n",
    "seed_everything(42)\n",
    "new_results2 = model_new.model.permutation_model(batch_size)\n",
    "print((new_results1[\"soft_perm_mat\"] - new_results2[\"soft_perm_mat\"]).abs().max())\n",
    "print((new_results1[\"hard_perm_mat\"] - new_results2[\"hard_perm_mat\"]).abs().max().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MaxBackward1>)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "old_results1 = model_old.model.permutation_model(batch_size)\n",
    "seed_everything(42)\n",
    "old_results2 = model_old.model.permutation_model(batch_size)\n",
    "print((old_results1[\"soft_perm_mat\"] - old_results2[\"soft_perm_mat\"]).abs().max())\n",
    "print((old_results1[\"hard_perm_mat\"] - old_results2[\"hard_perm_mat\"]).abs().max().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MaxBackward1>) torch.Size([50, 3, 3]) torch.Size([50, 3, 3])\n",
      "tensor(0.) torch.Size([4, 3, 3]) torch.Size([4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    (old_results1[\"soft_perm_mat\"] - new_results1[\"soft_perm_mat\"]).abs().max(),\n",
    "    new_results1[\"soft_perm_mat\"].shape,\n",
    "    old_results1[\"soft_perm_mat\"].shape,\n",
    ")\n",
    "print(\n",
    "    (old_results1[\"hard_perm_mat\"] - new_results1[\"hard_perm_mat\"]).abs().max().max(),\n",
    "    new_results1[\"hard_perm_mat\"].shape,\n",
    "    old_results1[\"hard_perm_mat\"].shape,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from lightning import seed_everything\n",
    "\n",
    "args = dict(\n",
    "    # num_hard_samples=100,\n",
    "    permutation_type=\"hard\",\n",
    "    # permutation_type='soft'\n",
    ")\n",
    "batch_size = 128\n",
    "\n",
    "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_args\"] = args\n",
    "seed_everything(42)\n",
    "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_cls\"] = \"ocd.models.permutation.LearnablePermutation\"\n",
    "model_new = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
    "model_config[\"init_args\"][\"model_args\"][\n",
    "    \"permutation_learner_cls\"\n",
    "] = \"ocd.models.permutation.LegacyLearnablePermutation\"\n",
    "model_old = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
    "model_new.model.permutation_model.gamma = model_old.model.permutation_model.gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "new_results1 = model_new.model.permutation_model(batch_size)\n",
    "seed_everything(42)\n",
    "new_results2 = model_new.model.permutation_model(batch_size)\n",
    "print((new_results1[\"perm_mat\"] - new_results2[\"perm_mat\"]).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) a\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "old_results1 = model_old.model.permutation_model(batch_size)\n",
    "seed_everything(42)\n",
    "old_results2 = model_old.model.permutation_model(batch_size)\n",
    "print((old_results1[\"perm_mat\"] - old_results2[\"perm_mat\"]).abs().max(), \"a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) torch.Size([128, 3, 3]) torch.Size([128, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    (old_results1[\"perm_mat\"] - new_results1[\"perm_mat\"]).abs().max(),\n",
    "    new_results1[\"perm_mat\"].shape,\n",
    "    old_results1[\"perm_mat\"].shape,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from lightning import seed_everything\n",
    "\n",
    "args = dict(\n",
    "    # num_hard_samples=100,\n",
    "    permutation_type=\"soft\",\n",
    "    # permutation_type='soft'\n",
    ")\n",
    "batch_size = 128\n",
    "\n",
    "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_args\"] = args\n",
    "seed_everything(42)\n",
    "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_cls\"] = \"ocd.models.permutation.LearnablePermutation\"\n",
    "model_new = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
    "model_config[\"init_args\"][\"model_args\"][\n",
    "    \"permutation_learner_cls\"\n",
    "] = \"ocd.models.permutation.LegacyLearnablePermutation\"\n",
    "model_old = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
    "model_new.model.permutation_model.gamma = model_old.model.permutation_model.gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "new_results1 = model_new.model.permutation_model(batch_size)\n",
    "seed_everything(42)\n",
    "new_results2 = model_new.model.permutation_model(batch_size)\n",
    "print((new_results1[\"perm_mat\"] - new_results2[\"perm_mat\"]).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "old_results1 = model_old.model.permutation_model(batch_size)\n",
    "seed_everything(42)\n",
    "old_results2 = model_old.model.permutation_model(batch_size)\n",
    "print((old_results1[\"perm_mat\"] - old_results2[\"perm_mat\"]).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MaxBackward1>) torch.Size([128, 3, 3]) torch.Size([128, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    (old_results1[\"perm_mat\"] - new_results1[\"perm_mat\"]).abs().max(),\n",
    "    new_results1[\"perm_mat\"].shape,\n",
    "    old_results1[\"perm_mat\"].shape,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from lightning import seed_everything\n",
    "\n",
    "args = dict(\n",
    "    # num_hard_samples=100,\n",
    "    permutation_type=\"hybrid-quantization\",\n",
    "    hard_from_softs=True,\n",
    ")\n",
    "batch_size = 128\n",
    "\n",
    "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_args\"] = args\n",
    "seed_everything(42)\n",
    "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_cls\"] = \"ocd.models.permutation.LearnablePermutation\"\n",
    "model_new = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
    "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_args\"].pop(\"hard_from_softs\")\n",
    "model_config[\"init_args\"][\"model_args\"][\n",
    "    \"permutation_learner_cls\"\n",
    "] = \"ocd.models.permutation.LegacyLearnablePermutation\"\n",
    "model_old = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
    "model_new.model.permutation_model.gamma = model_old.model.permutation_model.gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "new_results1 = model_new.model.permutation_model(batch_size)\n",
    "seed_everything(42)\n",
    "new_results2 = model_new.model.permutation_model(batch_size)\n",
    "print((new_results1[\"perm_mat\"] - new_results2[\"perm_mat\"]).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "old_results1 = model_old.model.permutation_model(batch_size)\n",
    "seed_everything(42)\n",
    "old_results2 = model_old.model.permutation_model(batch_size)\n",
    "print((old_results1[\"perm_mat\"] - old_results2[\"perm_mat\"]).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MaxBackward1>) torch.Size([128, 3, 3]) torch.Size([128, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    (old_results1[\"perm_mat\"] - new_results1[\"perm_mat\"]).abs().max(),\n",
    "    new_results1[\"perm_mat\"].shape,\n",
    "    old_results1[\"perm_mat\"].shape,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
