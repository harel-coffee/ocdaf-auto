{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "# set PYTORCH_ENABLE_MPS_FALLBACK=1 in your environment\n",
                "\n",
                "import os \n",
                "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
                "import yaml\n",
                "import torch\n",
                "import lightning_toolbox as ltb\n",
                "import lightning\n",
                "import dypy as dy\n",
                "import sys\n",
                "sys.path.append('..')\n",
                "from ocd.models.permutation.utils import all_permutations\n",
                "# import sys\n",
                "# import ocd\n",
                "# import random\n",
                "device = 'cpu'\n",
                "# create a random permutation of n numbers\n",
                "\n",
                "data_config = yaml.safe_load(\n",
                "    open(\"../experiments/intervention/data/chain-3.yml\", \"r\")\n",
                ")\n",
                "model_config = yaml.safe_load(open(\"../experiments/intervention/model.yml\", \"r\"))\n",
                "\n",
                "n = 30\n",
                "model_config[\"init_args\"][\"model_args\"][\"in_features\"] = n\n",
                "\n",
                "# setup fixed perm\n",
                "enforce_perm = torch.randperm(n).tolist()\n",
                "data_config[\"init_args\"][\"dataset_args\"][\"scm_generator_args\"][\"graph_generator_args\"][\n",
                "    \"enforce_ordering\"\n",
                "] = enforce_perm\n",
                "model_config[\"init_args\"][\"model_args\"][\"ordering\"] = enforce_perm\n",
                "model_config[\"init_args\"][\"model_args\"][\"scale_transform_s_args\"] = dict(post_act_scale=5.0, normalization=None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(LearnablePermutation(num_features=30, permutation_type=gumbel-topk),\n",
                            " LearnablePermutation(num_features=30))"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from lightning import seed_everything\n",
                "\n",
                "args = dict(\n",
                "    # num_hard_samples=100,\n",
                "    permutation_type=\"gumbel-topk\",\n",
                "    # permutation_type='soft'\n",
                "     maximum_basis_size=4,\n",
                ")\n",
                "batch_size = 512\n",
                "\n",
                "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_args\"] = args\n",
                "seed_everything(42)\n",
                "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_cls\"] = \"ocd.models.permutation._module_debugging.LearnablePermutation\"\n",
                "model_new = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
                "model_config[\"init_args\"][\"model_args\"][\n",
                "    \"permutation_learner_cls\"\n",
                "] = \"ocd.models.permutation.LearnablePermutation\"\n",
                "model_old = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
                "model_new.model.permutation_model.gamma = model_old.model.permutation_model.gamma\n",
                "model_new.model.permutation_model, model_old.model.permutation_model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 42\n",
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0., grad_fn=<MaxBackward1>)\n",
                        "tensor(0.)\n"
                    ]
                }
            ],
            "source": [
                "seed_everything(42)\n",
                "new_results1 = model_new.model.permutation_model(batch_size)\n",
                "seed_everything(42)\n",
                "new_results2 = model_new.model.permutation_model(batch_size)\n",
                "print((new_results1[\"soft_perm_mat\"] - new_results2[\"soft_perm_mat\"]).abs().max())\n",
                "print((new_results1[\"hard_perm_mat\"] - new_results2[\"hard_perm_mat\"]).abs().max().max())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 42\n",
                        "/Users/vahidzee/.pyenv/versions/3.10.9/envs/deep/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
                        "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0., grad_fn=<MaxBackward1>)\n",
                        "tensor(0.)\n"
                    ]
                }
            ],
            "source": [
                "seed_everything(42)\n",
                "old_results1 = model_old.model.permutation_model(batch_size)\n",
                "seed_everything(42)\n",
                "old_results2 = model_old.model.permutation_model(batch_size)\n",
                "print((old_results1[\"soft_perm_mat\"] - old_results2[\"soft_perm_mat\"]).abs().max())\n",
                "print((old_results1[\"hard_perm_mat\"] - old_results2[\"hard_perm_mat\"]).abs().max().max())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0., grad_fn=<MaxBackward1>) torch.Size([30, 30]) torch.Size([30, 30])\n",
                        "tensor(0.) torch.Size([4, 30, 30]) torch.Size([4, 30, 30])\n",
                        "tensor(0., grad_fn=<MaxBackward1>) torch.Size([4]) torch.Size([4])\n"
                    ]
                }
            ],
            "source": [
                "print(\n",
                "    (old_results1[\"soft_perm_mat\"] - new_results1[\"soft_perm_mat\"]).abs().max(),\n",
                "    new_results1[\"soft_perm_mat\"].shape,\n",
                "    old_results1[\"soft_perm_mat\"].shape,\n",
                ")\n",
                "print(\n",
                "    (old_results1[\"hard_perm_mat\"] - new_results1[\"hard_perm_mat\"]).abs().max().max(),\n",
                "    new_results1[\"hard_perm_mat\"].shape,\n",
                "    old_results1[\"hard_perm_mat\"].shape,\n",
                ")\n",
                "print(\n",
                "    (old_results1['scores'] - new_results1['score_grid']).abs().max().max(), old_results1['scores'].shape, new_results1['score_grid'].shape\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(LearnablePermutation(num_features=30, permutation_type=hard),\n",
                            " LearnablePermutation(num_features=30))"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from lightning import seed_everything\n",
                "\n",
                "args = dict(\n",
                "    # num_hard_samples=100,\n",
                "    permutation_type=\"hard\",\n",
                "    # permutation_type='soft'\n",
                ")\n",
                "batch_size = 512\n",
                "\n",
                "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_args\"] = args\n",
                "seed_everything(42)\n",
                "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_cls\"] = \"ocd.models.permutation._module_debugging.LearnablePermutation\"\n",
                "model_new = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
                "model_config[\"init_args\"][\"model_args\"][\n",
                "    \"permutation_learner_cls\"\n",
                "] = \"ocd.models.permutation.LearnablePermutation\"\n",
                "model_old = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
                "model_new.model.permutation_model.gamma = model_old.model.permutation_model.gamma\n",
                "model_new.model.permutation_model, model_old.model.permutation_model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 42\n",
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0.)\n"
                    ]
                }
            ],
            "source": [
                "seed_everything(42)\n",
                "new_results1 = model_new.model.permutation_model(batch_size)\n",
                "seed_everything(42)\n",
                "new_results2 = model_new.model.permutation_model(batch_size)\n",
                "print((new_results1[\"perm_mat\"] - new_results2[\"perm_mat\"]).abs().max())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 42\n",
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0.) a\n"
                    ]
                }
            ],
            "source": [
                "seed_everything(42)\n",
                "old_results1 = model_old.model.permutation_model(batch_size)\n",
                "seed_everything(42)\n",
                "old_results2 = model_old.model.permutation_model(batch_size)\n",
                "print((old_results1[\"perm_mat\"] - old_results2[\"perm_mat\"]).abs().max(), \"a\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0.) torch.Size([512, 30, 30]) torch.Size([512, 30, 30])\n"
                    ]
                }
            ],
            "source": [
                "print(\n",
                "    (old_results1[\"perm_mat\"] - new_results1[\"perm_mat\"]).abs().max(),\n",
                "    new_results1[\"perm_mat\"].shape,\n",
                "    old_results1[\"perm_mat\"].shape,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(LearnablePermutation(num_features=30), LearnablePermutation(num_features=30))"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from lightning import seed_everything\n",
                "\n",
                "args = dict(\n",
                "    # num_hard_samples=100,\n",
                "    permutation_type=\"soft\",\n",
                "    # permutation_type='soft'\n",
                ")\n",
                "batch_size = 512\n",
                "\n",
                "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_args\"] = args\n",
                "seed_everything(42)\n",
                "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_cls\"] = \"ocd.models.permutation._module_debugging.LearnablePermutation\"\n",
                "model_new = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
                "model_config[\"init_args\"][\"model_args\"][\n",
                "    \"permutation_learner_cls\"\n",
                "] = \"ocd.models.permutation.LearnablePermutation\"\n",
                "model_old = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
                "model_new.model.permutation_model.gamma = model_old.model.permutation_model.gamma\n",
                "model_new.model.permutation_model, model_old.model.permutation_model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 42\n",
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0., grad_fn=<MaxBackward1>)\n"
                    ]
                }
            ],
            "source": [
                "seed_everything(42)\n",
                "new_results1 = model_new.model.permutation_model(batch_size)\n",
                "seed_everything(42)\n",
                "new_results2 = model_new.model.permutation_model(batch_size)\n",
                "print((new_results1[\"perm_mat\"] - new_results2[\"perm_mat\"]).abs().max())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 42\n",
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0., grad_fn=<MaxBackward1>)\n"
                    ]
                }
            ],
            "source": [
                "seed_everything(42)\n",
                "old_results1 = model_old.model.permutation_model(batch_size)\n",
                "seed_everything(42)\n",
                "old_results2 = model_old.model.permutation_model(batch_size)\n",
                "print((old_results1[\"perm_mat\"] - old_results2[\"perm_mat\"]).abs().max())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0., grad_fn=<MaxBackward1>) torch.Size([512, 30, 30]) torch.Size([512, 30, 30])\n"
                    ]
                }
            ],
            "source": [
                "print(\n",
                "    (old_results1[\"perm_mat\"] - new_results1[\"perm_mat\"]).abs().max(),\n",
                "    new_results1[\"perm_mat\"].shape,\n",
                "    old_results1[\"perm_mat\"].shape,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(LearnablePermutation(num_features=30, permutation_type=hybrid-straight-through),\n",
                            " LearnablePermutation(num_features=30))"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from lightning import seed_everything\n",
                "\n",
                "args = dict(\n",
                "    # num_hard_samples=100,\n",
                "    permutation_type=\"hybrid-straight-through\",\n",
                "    hard_from_softs=True,\n",
                ")\n",
                "batch_size = 512\n",
                "\n",
                "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_args\"] = args\n",
                "seed_everything(42)\n",
                "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_cls\"] = \"ocd.models.permutation._module_debugging.LearnablePermutation\"\n",
                "model_new = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
                "model_config[\"init_args\"][\"model_args\"][\n",
                "    \"permutation_learner_cls\"\n",
                "] = \"ocd.models.permutation.LearnablePermutation\"\n",
                "args = dict(\n",
                "    # num_hard_samples=100,\n",
                "    permutation_type=\"straight-through\",\n",
                ")\n",
                "batch_size = 512\n",
                "\n",
                "model_config[\"init_args\"][\"model_args\"][\"permutation_learner_args\"] = args\n",
                "model_old = dy.eval(model_config[\"class_path\"])(**model_config[\"init_args\"])\n",
                "model_new.model.permutation_model.gamma = model_old.model.permutation_model.gamma\n",
                "model_new.model.permutation_model, model_old.model.permutation_model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 42\n",
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0., grad_fn=<MaxBackward1>)\n"
                    ]
                }
            ],
            "source": [
                "seed_everything(42)\n",
                "new_results1 = model_new.model.permutation_model(batch_size)\n",
                "seed_everything(42)\n",
                "new_results2 = model_new.model.permutation_model(batch_size)\n",
                "print((new_results1[\"perm_mat\"] - new_results2[\"perm_mat\"]).abs().max())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 42\n",
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0., grad_fn=<MaxBackward1>)\n"
                    ]
                }
            ],
            "source": [
                "seed_everything(42)\n",
                "old_results1 = model_old.model.permutation_model(batch_size)\n",
                "seed_everything(42)\n",
                "old_results2 = model_old.model.permutation_model(batch_size)\n",
                "print((old_results1[\"perm_mat\"] - old_results2[\"perm_mat\"]).abs().max())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0., grad_fn=<MaxBackward1>) torch.Size([512, 30, 30]) torch.Size([512, 30, 30])\n"
                    ]
                }
            ],
            "source": [
                "print(\n",
                "    (old_results1[\"perm_mat\"] - new_results1[\"perm_mat\"]).abs().max(),\n",
                "    new_results1[\"perm_mat\"].shape,\n",
                "    old_results1[\"perm_mat\"].shape,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ocd.models.permutation.utils import sinkhorn, sample_gumbel_noise, hungarian, listperm2matperm\n",
                "\n",
                "num_features = 10\n",
                "num_samples = 10000\n",
                "num_iters = 50\n",
                "tau = 0.1\n",
                "gamma = torch.randn(num_features, num_features)\n",
                "f = lambda x: -torch.nn.functional.logsigmoid(x)\n",
                "# f = lambda x: x\n",
                "\n",
                "noise = sample_gumbel_noise(num_samples, num_features, num_features, device=device) * 1\n",
                "soft_noise_in = sinkhorn(f((gamma) + noise) / tau, num_iters=num_iters)\n",
                "soft_noise_out = sinkhorn(f((gamma)) / tau, num_iters=num_iters) + noise / tau\n",
                "\n",
                "# generate soft permutaiton\n",
                "hard_plain = hungarian((f(gamma) + noise) / tau)\n",
                "hard_soft_in = hungarian(soft_noise_in)\n",
                "hard_soft_in_1 = hungarian(sinkhorn(f((gamma) + noise) / tau, num_iters=1))\n",
                "hard_soft_out = hungarian(soft_noise_out)\n",
                "\n",
                "torch.unique(hard_plain, dim=0).shape, torch.unique(hard_soft_in, dim=0).shape, torch.unique(\n",
                "    hard_soft_out, dim=0\n",
                ").shape, torch.unique(hard_soft_in_1, dim=0).shape\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "deep",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}