class_path: lightning_toolbox.TrainingModule
init_args:
  # the model
  model_cls: ocd.models.ocdaf.OCDAF
  model_args:
    use_permutation: False
    base_distribution: torch.distributions.Normal
    base_distribution_args:
      loc: 0.0
      scale: 1.0
    in_features: 3
    layers: [3, 3, 3]
    num_transforms: 3
    additive: False
    elementwise_perm: True
    ordering: [0, 2, 1]
    residual: False
    bias: true
    activation: torch.nn.LeakyReLU
    activation_args:
      negative_slope: 0.1
  # the optimizer
  optimizer: torch.optim.Adam
  lr: 0.001
  # scheduler: torch.optim.lr_scheduler.ReduceLROnPlateau
  # scheduler_args:
  #   mode: "min"
  #   factor: 0.75
  #   patience: 10
  # scheduler_name: "lr_scheduler"
  # scheduler_interval: "epoch"
  # scheduler_monitor: loss/val
  # the loss
  objective_args:
    nll: >
      lambda training_module, batch: -training_module.model(batch)['log_prob'].mean()
