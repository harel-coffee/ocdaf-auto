# callbacks
callbacks:
  - class_path: lightning.pytorch.callbacks.lr_monitor.LearningRateMonitor
    init_args:
      logging_interval: step
  - class_path: ocd.training.callbacks.data_visualizer.DataVisualizer
  - class_path: ocd.training.callbacks.phase_changer.PhaseChangerCallback
    init_args:
      starting_phase: maximization
      # Set to higher value for faster results
      check_every_n_iterations: 1
      # The settings regarding epoch limit values
      maximization_epoch_limit: 50
      expectation_epoch_limit: 50
      # The settings regarding the generalization gap
      generalization_early_stopping: []
      generalization_patience: 10
      generalization_threshold_eps: 0.01
  - class_path: ocd.training.callbacks.birkhoff_visualizer.BirkhoffCallback
    init_args:
      epoch_buffer_size: 1
      evaluate_every_n_epochs: 100
      permutation_size: 5
      seed: 666
      write_cost_values: True
      write_permutation_names: True
      core_points_has_birkhoff_vertices: True
      core_points_has_birkhoff_edges: False
      reject_outlier_factor: 0.1
      # Including correct orderings
      ordering_to_score_mapping: 
        1-0-2-3-4 : 2
        1-0-2-4-3 : 3
        1-0-3-2-4 : 3
        1-0-3-4-2 : 4
        1-0-4-2-3 : 4
        1-0-4-3-2 : 5
        1-2-0-3-4 : 1
        1-2-0-4-3 : 2
        1-2-3-0-4 : 0
        1-2-3-4-0 : 1
        1-2-4-0-3 : 3
        1-2-4-3-0 : 2
        1-3-0-2-4 : 2
        1-3-0-4-2 : 3
        1-3-2-0-4 : 1
        1-3-2-4-0 : 2
        1-3-4-0-2 : 4
        1-3-4-2-0 : 3
        1-4-0-2-3 : 5
        1-4-0-3-2 : 6
        1-4-2-0-3 : 4
        1-4-2-3-0 : 3
        1-4-3-0-2 : 5
        1-4-3-2-0 : 4
        0-1-2-3-4 : 3
        0-1-2-4-3 : 4
        0-1-3-2-4 : 4
        0-1-3-4-2 : 5
        0-1-4-2-3 : 5
        0-1-4-3-2 : 6
        0-2-1-3-4 : 4
        0-2-1-4-3 : 5
        0-2-3-1-4 : 5
        0-2-3-4-1 : 6
        0-2-4-1-3 : 6
        0-2-4-3-1 : 7
        0-3-1-2-4 : 5
        0-3-1-4-2 : 6
        0-3-2-1-4 : 6
        0-3-2-4-1 : 7
        0-3-4-1-2 : 7
        0-3-4-2-1 : 8
        0-4-1-2-3 : 6
        0-4-1-3-2 : 7
        0-4-2-1-3 : 7
        0-4-2-3-1 : 8
        0-4-3-1-2 : 8
        0-4-3-2-1 : 9
        2-1-0-3-4 : 2
        2-1-0-4-3 : 3
        2-1-3-0-4 : 1
        2-1-3-4-0 : 2
        2-1-4-0-3 : 4
        2-1-4-3-0 : 3
        2-0-1-3-4 : 3
        2-0-1-4-3 : 4
        2-0-3-1-4 : 4
        2-0-3-4-1 : 5
        2-0-4-1-3 : 5
        2-0-4-3-1 : 6
        2-3-1-0-4 : 2
        2-3-1-4-0 : 3
        2-3-0-1-4 : 3
        2-3-0-4-1 : 4
        2-3-4-1-0 : 4
        2-3-4-0-1 : 5
        2-4-1-0-3 : 5
        2-4-1-3-0 : 4
        2-4-0-1-3 : 6
        2-4-0-3-1 : 7
        2-4-3-1-0 : 5
        2-4-3-0-1 : 6
        3-1-0-2-4 : 3
        3-1-0-4-2 : 4
        3-1-2-0-4 : 2
        3-1-2-4-0 : 3
        3-1-4-0-2 : 5
        3-1-4-2-0 : 4
        3-0-1-2-4 : 4
        3-0-1-4-2 : 5
        3-0-2-1-4 : 5
        3-0-2-4-1 : 6
        3-0-4-1-2 : 6
        3-0-4-2-1 : 7
        3-2-1-0-4 : 3
        3-2-1-4-0 : 4
        3-2-0-1-4 : 4
        3-2-0-4-1 : 5
        3-2-4-1-0 : 5
        3-2-4-0-1 : 6
        3-4-1-0-2 : 6
        3-4-1-2-0 : 5
        3-4-0-1-2 : 7
        3-4-0-2-1 : 8
        3-4-2-1-0 : 6
        3-4-2-0-1 : 7
        4-1-0-2-3 : 6
        4-1-0-3-2 : 7
        4-1-2-0-3 : 5
        4-1-2-3-0 : 4
        4-1-3-0-2 : 6
        4-1-3-2-0 : 5
        4-0-1-2-3 : 7
        4-0-1-3-2 : 8
        4-0-2-1-3 : 8
        4-0-2-3-1 : 9
        4-0-3-1-2 : 9
        4-0-3-2-1 : 10
        4-2-1-0-3 : 6
        4-2-1-3-0 : 5
        4-2-0-1-3 : 7
        4-2-0-3-1 : 8
        4-2-3-1-0 : 6
        4-2-3-0-1 : 7
        4-3-1-0-2 : 7
        4-3-1-2-0 : 6
        4-3-0-1-2 : 8
        4-3-0-2-1 : 9
        4-3-2-1-0 : 7
        4-3-2-0-1 : 8
      # Include permutation names
      add_permutation_to_name: True
  - class_path: ocd.training.callbacks.save_results.SavePermutationResultsCallback
    init_args:
      save_path: experiments/dummy/trainer-5
      save_every_n_epochs: 100
      num_samples: 1000
# device
accelerator: gpu
devices: 1
num_nodes: 0
# optimization
gradient_clip_algorithm: value
gradient_clip_val: 1.0
# precision: 16
# limits & training loop controls
max_epochs: 10000
log_every_n_steps: 1
check_val_every_n_epoch: 1
# tracking & debugging
# track_grad_norm: inf
# logger is setup while initializing the trainer
enable_checkpointing: true
enable_model_summary: true
enable_progress_bar: false
logger:
  class_path: lightning.pytorch.loggers.WandbLogger
  init_args:
    project: temporary-permutation
    name: full-pipeline-5
    checkpoint_name: full-pipeline
