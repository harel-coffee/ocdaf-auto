# This is a sweep on different hyper parameters for the final model that we are using
project: hyperparam-sweep
checkpoint_interval: 30
default_root_dir: experiments/sweep
use_smart_trainer: True
agent_run_args:
  count: 1
sweep_configuration:
  method: random
  metric:
    goal: minimize
    name: metrics/average-backward_relative_penalty
  parameters:
    trainer:
      callbacks:
        sweep: True
        sweep_identifier: PhaseChanging
        sweep_alias:
          - maximization50
          - maximization100
          - maximization200
        values:
          - sweep_list_operations:
              - sweep_overwrite: 0
            init_args:
              maximization_epoch_limit: 50
              expectation_epoch_limit: 20
              patience: 10
              cooldown: 10
          - sweep_list_operations:
              - sweep_overwrite: 0
            init_args:
              maximization_epoch_limit: 100
              expectation_epoch_limit: 50
              patience: 15
              cooldown: 25
          - sweep_list_operations:
              - sweep_overwrite: 0
            init_args:
              maximization_epoch_limit: 200
              expectation_epoch_limit: 50
              patience: 20
              cooldown: 50
    model:
      init_args:
        model_args:
          sweep_group_architecture:
            sweep_identifier: MLPArchitecture
            sweep: True
            sweep_alias:
              - SimplePopulate
              - ComplexPopulate
              - Fixed
            values:
              - layers: [5, 15, 5]
                populate_features: True
              - layers: [10, 30, 30, 10]
                populate_features: True
              - layers: [100, 300, 50]
                populate_features: False
        lr:
          - sweep: True
            sweep_identifier: lr_flow
            values: [0.01, 0.05]
          - sweep: True
            sweep_identifier: lr_gamma
            values: [0.01, 0.001]
        sweep_group_weight_decay:
          sweep_identifier: WeightDecay
          sweep: True
          sweep_alias:
            - medium_weight
            - large_weight
          values:
            - optimizer_args:
                - weight_decay: 0.1
                - weight_decay: 0.01
            - optimizer_args:
                - weight_decay: 1
                - weight_decay: 0.05
    seed_everything: 42

    sweep_group_datasets:
      sweep_identifier: DataBasisSizeAndEpoch
      sweep: True
      sweep_alias:
        - Sin-Erdos-25-Epoch-3000
        - NonParam-Chain-10-Epoch-3000
        - Cube-Full-5-Epoch-1500
        - Sin-Full-3-Epoch-300
      values:
        - data:
          init_args:
            dataset_args:
              name: parametric_normal_modulated_25_2048_erdos_renyi_sin_plus_x
              scm_generator: ocd.data.synthetic.ParametricSCMGenerator
              scm_generator_args:
                graph_generator: ocd.data.scm.GraphGenerator
                graph_generator_args:
                  graph_type: erdos_renyi
                  n: 25
                  p: 0.4
                  seed: 282
                noise_parameters: { loc: 0.0, scale: 1.0 }
                noise_type: normal
                s_function:
                  function_descriptor: |
                    def func(x):
                      x[x < 100] = numpy.log(1 + numpy.exp(x[x < 100]))
                      return x
                  function_of_interest: func
                s_function_signature: softplus
                seed: 979
                t_function:
                  function_descriptor: |
                    def func(x):
                      return numpy.sin(x) + x
                  function_of_interest: func
                t_function_signature: sin_plus_x
                weight_s: [0.5, 1.5]
                weight_t: [0.5, 1.5]
          trainer:
            max_epochs: 3000
          model:
            init_args:
              model_args:
                permutation_learner_args:
                  maximum_basis_size: 64
              scheduler_args:
                - patience: 100
                - patience: 100
        - data:
          init_args:
            dataset_args:
              name: non_parametric_non_linear_gaussian_10_2048_chain
              scm_generator: ocd.data.synthetic.GaussianProcessBasedSCMGeberator
              scm_generator_args:
                graph_generator: ocd.data.scm.GraphGenerator
                graph_generator_args:
                  graph_type: chain
                  n: 10
                  seed: 83
                noise_mean: 0.0
                noise_std: 1.0
                s_gamma_rbf_kernel: 1.0
                s_mean_function_activation:
                  function_descriptor: |
                    def func(x):
                      x[x < 100] = numpy.log(1 + numpy.exp(x[x < 100]))
                      return x
                  function_of_interest: func
                s_mean_function_activation_signature: softplus
                s_mean_function_weights: [0.01, 0.1]
                s_variance_rbf_kernel: 1.0
                seed: 204
                t_mean_function_activation:
                  function_descriptor: |
                    def func(x):
                      return numpy.sin(x) + x
                  function_of_interest: func
                t_mean_function_activation_signature: sin_plus_x
                t_mean_function_weights: [0.01, 0.1]
                t_variance_rbf_kernel: 1.0
          trainer:
            max_epochs: 3000
          model:
            init_args:
              model_args:
                permutation_learner_args:
                  maximum_basis_size: 64
              scheduler_args:
                - patience: 100
                - patience: 100
        - data:
          init_args:
            dataset_args:
              name: parametric_normal_modulated_5_2048_full_cube_dislocate
              scm_generator: ocd.data.synthetic.ParametricSCMGenerator
              scm_generator_args:
                graph_generator: ocd.data.scm.GraphGenerator
                graph_generator_args:
                  graph_type: full
                  n: 5
                  seed: 136
                noise_parameters:
                  loc: 0.0
                  scale: 1.0
                noise_type: normal
                s_function:
                  function_descriptor: |
                    def func(x):
                      x[x < 100] = numpy.log(1 + numpy.exp(x[x < 100]))
                      return x
                  function_of_interest: func
                s_function_signature: softplus
                seed: 419
                t_function:
                  function_descriptor: |
                    def func(x):
                      x[x > 100] = 100
                      x[x < -100] = -100
                      x_mean = numpy.mean(x)
                      x_std = numpy.std(x)
                      if x_std == 0:
                        x_std = 1
                      x = (x - x_mean) / x_std
                      ret = x**3 + 6
                      return ret
                  function_of_interest: func
                t_function_signature: cube_and_dislocate
                weight_s: [0.5, 1.5]
                weight_t: [0.5, 1.5]
          trainer:
            max_epochs: 1500
          model:
            init_args:
              model_args:
                permutation_learner_args:
                  maximum_basis_size: 10
              scheduler_args:
                - patience: 50
                - patience: 50
        - data:
          init_args:
            dataset_args:
              name: parametric_normal_modulated_3_2048_full_sin_plus_x
              scm_generator: ocd.data.synthetic.ParametricSCMGenerator
              scm_generator_args:
                graph_generator: ocd.data.scm.GraphGenerator
                graph_generator_args:
                  graph_type: full
                  n: 3
                  seed: 582
                noise_parameters:
                  loc: 0.0
                  scale: 1.0
                noise_type: normal
                s_function:
                  function_descriptor: |
                    def func(x):
                      x[x < 100] = numpy.log(1 + numpy.exp(x[x < 100]))
                      return x
                  function_of_interest: func
                s_function_signature: softplus
                seed: 780
                t_function:
                  function_descriptor: |
                    def func(x):
                      return numpy.sin(x) + x
                  function_of_interest: func
                t_function_signature: sin_plus_x
                weight_s: [0.5, 1.5]
                weight_t: [0.5, 1.5]
          trainer:
            max_epochs: 300
          model:
            init_args:
              model_args:
                permutation_learner_args:
                  maximum_basis_size: 10
              scheduler_args:
                - patience: 10
                - patience: 10
