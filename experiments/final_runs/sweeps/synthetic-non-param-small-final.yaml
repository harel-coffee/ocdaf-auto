# This is a sweep on different phase changing strategies and how
# it can affect the training process for larger datasets
project: synthetic-run-non-parametric-small
checkpoint_interval: 30
default_root_dir: experiments/sweep
use_smart_trainer: True
agent_run_args:
  count: 10000
sweep_configuration:
  method: grid
  metric:
    goal: minimize
    name: metrics/average-backward_relative_penalty
  parameters:
    sweep_group_B_additive_affine:
      sweep: True
      sweep_identifier: B_additive_affine
      sweep_alias:
        - affine
        - additive
      values:
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_affine")
                scm_generator_args:
                  s_pos_function: >
                    sweep_eval(lambda x: x)
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_additive")
                scm_generator_args:
                  s_pos_function:
                    function_descriptor: |
                      def func(x):
                        return numpy.ones_like(x)
                    function_of_interest: func
                  s_pos_function_signature: one
    sweep_group_C_graph_size:
      sweep: True
      sweep_identifier: C_graph_size_and_scheduling
      sweep_alias:
        - n3
        - n4
        - n5
        - n6
      values:
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_n3")
                scm_generator_args:
                  graph_generator_args:
                    n: 3
          trainer:
            max_epochs: 1000
            # max_epochs: 1
            callbacks:
              sweep_list_operations:
                - sweep_overwrite: 1
              init_args:
                maximization_epoch_limit: 60
                expectation_epoch_limit: 45
                patience: 15
                cooldown: 200
          model:
            init_args:
              scheduler_args:
                - factor: 0.5
                  patience: 55
                - factor: 0.5
                  patience: 45
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_n4")
                scm_generator_args:
                  graph_generator_args:
                    n: 4
          trainer:
            max_epochs: 1500
            # max_epochs: 1
            callbacks:
              sweep_list_operations:
                - sweep_overwrite: 1
              init_args:
                maximization_epoch_limit: 80
                expectation_epoch_limit: 55
                patience: 15
                cooldown: 200
          model:
            init_args:
              scheduler_args:
                - factor: 0.5
                  patience: 70
                - factor: 0.5
                  patience: 55
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_n5")
                scm_generator_args:
                  graph_generator_args:
                    n: 5
          trainer:
            max_epochs: 2200
            # max_epochs: 1
            callbacks:
              sweep_list_operations:
                - sweep_overwrite: 1
              init_args:
                maximization_epoch_limit: 90
                expectation_epoch_limit: 65
                patience: 15
                cooldown: 200
          model:
            init_args:
              scheduler_args:
                - factor: 0.5
                  patience: 100
                - factor: 0.5
                  patience: 60
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_n6")
                scm_generator_args:
                  graph_generator_args:
                    n: 6
          trainer:
            max_epochs: 3200
            # max_epochs: 1
            callbacks:
              sweep_list_operations:
                - sweep_overwrite: 1
              init_args:
                maximization_epoch_limit: 100
                expectation_epoch_limit: 80
                patience: 15
                cooldown: 200
          model:
            init_args:
              scheduler_args:
                - factor: 0.5
                  patience: 140
                - factor: 0.5
                  patience: 110
    sweep_group_F_graph_type:
      sweep: True
      sweep_identifier: F_graph_type
      sweep_alias:
        - erdos
        - chain
        - full
      values:
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_erdos")
                scm_generator_args:
                  graph_generator_args:
                    graph_type: erdos_renyi
                    p: 0.4
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_chain")
                scm_generator_args:
                  graph_generator_args:
                    graph_type: chain
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_full")
                scm_generator_args:
                  graph_generator_args:
                    graph_type: full
    sweep_group_G_seeds:
      sweep: True
      sweep_identifier: G_seed
      sweep_alias:
        - seedset0
        - seedset1
        - seedset2
        - seedset3
        - seedset4
      values:
        - seed_everything: 10
          data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_seed0")
                seed: 11
                scm_generator_args:
                  seed: 13
                  graph_generator_args:
                    seed: 14
        - seed_everything: 20
          data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_seed1")
                seed: 21
                scm_generator_args:
                  seed: 23
                  graph_generator_args:
                    seed: 24
        - seed_everything: 30
          data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_seed2")
                seed: 21
                scm_generator_args:
                  seed: 23
                  graph_generator_args:
                    seed: 24
        - seed_everything: 40
          data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_seed3")
                seed: 41
                scm_generator_args:
                  seed: 43
                  graph_generator_args:
                    seed: 44
        - seed_everything: 50
          data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_seed4")
                seed: 51
                scm_generator_args:
                  seed: 53
                  graph_generator_args:
                    seed: 54
    sweep_group_H_methods:
      sweep_identifier: H_methods
      sweep: True
      sweep_alias:
        - gumbel_top_k
        - straight_through_sinkhorn_no_standard
      values:
        - model:
            init_args:
              model_args:
                permutation_learner_args:
                  permutation_type: gumbel-topk
        - model:
            init_args:
              model_args:
                permutation_learner_args:
                  permutation_type: straight-through
          data:
            init_args:
              dataset_args:
                standardization: False
                reject_outliers_n_far_from_mean: null
