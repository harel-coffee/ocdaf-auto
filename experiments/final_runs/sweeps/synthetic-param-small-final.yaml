# This is a sweep on different phase changing strategies and how
# it can affect the training process for larger datasets
project: synthetic-run-parametric-small
checkpoint_interval: 30
default_root_dir: experiments/sweep
use_smart_trainer: True
agent_run_args:
  count: 10000
sweep_configuration:
  method: random
  metric:
    goal: minimize
    name: metrics/average-backward_relative_penalty
  parameters:
    sweep_group_Y_linearity:
      sweep: True
      sweep_identifier: A_linearity
      sweep_alias:
        - non_lienar
        - linear
      values:
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_non_linear")
                scm_generator_args:
                  s_function: >
                    sweep_eval(lambda x: x)
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_linear")
                scm_generator_args:
                  s_function:
                    # we perform normalization for same variance not to work
                    function_descriptor: |
                      def func(x):
                        numpy.random.seed(int(numpy.mean(x)))
                        return numpy.random.uniform() * numpy.ones_like(x)
                    function_of_interest: func
                  s_function_signature: steady
                  t_function:
                    # we perform normalization for varsort not to work
                    function_descriptor: |
                      def func(x):
                        x[x > 100] = 100
                        x[x < -100] = -100
                        x_mean = numpy.mean(x)
                        x_std = numpy.std(x)
                        if x_std == 0:
                          x_std = 1
                        x = (x - x_mean) / x_std
                        return x
                    function_of_interest: func
                  t_function_signature: ident_normalize
    sweep_group_Z_additive_affine:
      sweep: True
      sweep_identifier: B_additive_affine
      sweep_alias:
        - affine
        - additive
      values:
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_affine")
                scm_generator_args:
                  s_function: >
                    sweep_eval(lambda x: x)
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_additive")
                scm_generator_args:
                  s_function:
                    function_descriptor: |
                      def func(x):
                        return numpy.ones_like(x)
                    function_of_interest: func
                  s_function_signature: one
    sweep_group_C_graph_size:
      sweep: True
      sweep_identifier: C_graph_size_and_scheduling
      sweep_alias:
        - n3
        - n4
        - n5
        - n6
      values:
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_n3")
                scm_generator_args:
                  graph_generator_args:
                    n: 3
          trainer:
            max_epochs: 1000
            # max_epochs: 1
            callbacks:
              sweep_list_operations:
                - sweep_overwrite: 1
              init_args:
                maximization_epoch_limit: 60
                expectation_epoch_limit: 45
                patience: 15
                cooldown: 200
          model:
            init_args:
              scheduler_args:
                - factor: 0.5
                  patience: 55
                - factor: 0.5
                  patience: 45
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_n4")
                scm_generator_args:
                  graph_generator_args:
                    n: 4
          trainer:
            max_epochs: 1500
            # max_epochs: 1
            callbacks:
              sweep_list_operations:
                - sweep_overwrite: 1
              init_args:
                maximization_epoch_limit: 80
                expectation_epoch_limit: 55
                patience: 15
                cooldown: 200
          model:
            init_args:
              scheduler_args:
                - factor: 0.5
                  patience: 70
                - factor: 0.5
                  patience: 55
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_n5")
                scm_generator_args:
                  graph_generator_args:
                    n: 5
          trainer:
            max_epochs: 2200
            # max_epochs: 1
            callbacks:
              sweep_list_operations:
                - sweep_overwrite: 1
              init_args:
                maximization_epoch_limit: 90
                expectation_epoch_limit: 65
                patience: 15
                cooldown: 200
          model:
            init_args:
              scheduler_args:
                - factor: 0.5
                  patience: 100
                - factor: 0.5
                  patience: 60
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_n6")
                scm_generator_args:
                  graph_generator_args:
                    n: 6
          trainer:
            max_epochs: 3200
            # max_epochs: 1
            callbacks:
              sweep_list_operations:
                - sweep_overwrite: 1
              init_args:
                maximization_epoch_limit: 100
                expectation_epoch_limit: 80
                patience: 15
                cooldown: 200
          model:
            init_args:
              scheduler_args:
                - factor: 0.5
                  patience: 140
                - factor: 0.5
                  patience: 110
    sweep_group_D_noise_type:
      sweep: True
      sweep_identifier: D_noise_type
      sweep_alias:
        - normal
        - laplace
      values:
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_normal")
                scm_generator_args:
                  noise_type: normal
                  noise_parameters:
                    loc: 0.0
                    scale: 1.0
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_laplace")
                scm_generator_args:
                  noise_type: laplace
                  noise_parameters:
                    loc: 0.0
                    scale: 1.0
    sweep_group_E_function_type:
      sweep: True
      sweep_identifier: E_function_type
      sweep_alias:
        - sin_plus_x
        - cubed_dislocate
      values:
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_SinPlusX")
                scm_generator_args:
                  t_function:
                    function_descriptor: |
                      def func(x):
                        return numpy.sin(x) + x
                    function_of_interest: func
                  t_function_signature: sin_plus_x
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_CubeDislocate")
                scm_generator_args:
                  t_function:
                    function_descriptor: |
                      def func(x):
                        x[x > 100] = 100
                        x[x < -100] = -100
                        x_mean = numpy.mean(x)
                        x_std = numpy.std(x)
                        if x_std == 0:
                          x_std = 1
                        x = (x - x_mean) / x_std
                        ret = x**3 + 6
                        return ret
                    function_of_interest: func
                  t_function_signature: cube_and_dislocate
    sweep_group_F_graph_type:
      sweep: True
      sweep_identifier: F_graph_type
      sweep_alias:
        - erdos
        - chain
        - full
      values:
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_erdos")
                scm_generator_args:
                  graph_generator_args:
                    graph_type: erdos_renyi
                    p: 0.4
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_chain")
                scm_generator_args:
                  graph_generator_args:
                    graph_type: chain
        - data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_full")
                scm_generator_args:
                  graph_generator_args:
                    graph_type: full
    sweep_group_G_seeds:
      sweep: True
      sweep_identifier: G_seed
      sweep_alias:
        - seedset0
        - seedset1
        - seedset2
        - seedset3
        - seedset4
      values:
        - seed_everything: 10
          data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_seed0")
                seed: 11
                scm_generator_args:
                  seed: 13
                  graph_generator_args:
                    seed: 14
        - seed_everything: 20
          data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_seed1")
                seed: 21
                scm_generator_args:
                  seed: 23
                  graph_generator_args:
                    seed: 24
        - seed_everything: 30
          data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_seed2")
                seed: 21
                scm_generator_args:
                  seed: 23
                  graph_generator_args:
                    seed: 24
        - seed_everything: 40
          data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_seed3")
                seed: 41
                scm_generator_args:
                  seed: 43
                  graph_generator_args:
                    seed: 44
        - seed_everything: 50
          data:
            init_args:
              dataset_args:
                name: >
                  sweep_eval(lambda x: f"{x}_seed4")
                seed: 51
                scm_generator_args:
                  seed: 53
                  graph_generator_args:
                    seed: 54
    sweep_group_H_methods:
      sweep_identifier: H_methods
      sweep: True
      sweep_alias:
        - gumbel_top_k
        - straight_through_sinkhorn_no_standard
        - straight_through_sinkhorn_with_standard
      values:
        - model:
            init_args:
              model_args:
                permutation_learner_args:
                  permutation_type: hybrid-sparse-map-simulator
        - model:
            init_args:
              model_args:
                permutation_learner_args:
                  permutation_type: hybrid-quantization
          data:
            init_args:
              dataset_args:
                standardization: False
                reject_outliers_n_far_from_mean: null
        - model:
            init_args:
              model_args:
                permutation_learner_args:
                  permutation_type: hybrid-quantization
          data:
            init_args:
              dataset_args:
                standardization: True
                reject_outliers_n_far_from_mean: 5
