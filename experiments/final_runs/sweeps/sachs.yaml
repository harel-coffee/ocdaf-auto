# This is a sweep on different phase changing strategies and how
# it can affect the training process for larger datasets
project: sachs
checkpoint_interval: 30
default_root_dir: experiments/sweep
use_smart_trainer: True
agent_run_args:
  count: 10000
sweep_configuration:
  method: grid
  metric:
    goal: minimize
    name: metrics/average-backward_relative_penalty
  parameters:
    sweep_group_A_seed_everything:
      sweep: True
      sweep_identifier: B_seed
      sweep_alias:
        - seed100
        - seed200
        - seed300
        - seed400
        - seed500
      values:
        - seed_everything: 100
        - seed_everything: 200
        - seed_everything: 300
        - seed_everything: 400
        - seed_everything: 500
    sweep_group_B_epoch_scheduling:
      sweep: True
      sweep_identifier: A_scheduling
      sweep_alias:
        - fast3000
        - slow6000
      values:
        - trainer:
            max_epochs: 3000
            callbacks:
              sweep_list_operations:
                - sweep_overwrite: 0
              init_args:
                maximization_epoch_limit: 100
                expectation_epoch_limit: 80
                patience: 15
                cooldown: 200
          model:
            init_args:
              scheduler_args:
                - factor: 0.5
                  patience: 130
                - factor: 0.5
                  patience: 110
        - trainer:
            max_epochs: 6000
            callbacks:
              sweep_list_operations:
                - sweep_overwrite: 0
              init_args:
                maximization_epoch_limit: 120
                expectation_epoch_limit: 100
                patience: 15
                cooldown: 200
          model:
            init_args:
              scheduler_args:
                - factor: 0.5
                  patience: 250
                - factor: 0.5
                  patience: 210
