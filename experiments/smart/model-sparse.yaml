class_path: ocd.training.module.OCDafTrainingModule
init_args:
  # the model
  model_cls: ocd.models.ocdaf.OCDAF
  model_args:
    # Permutation learner arguments
    use_permutation: True
    permutation_learner_cls: ocd.models.permutation.LearnablePermutation
    permutation_learner_args:
      gumbel_noise_std: >
        lambda self, training_module, **kwargs: 2 - (2 / (training_module.trainer.max_epochs)) * (training_module.current_epoch) 
      permutation_type: hybrid-sparse-map-simulator
      buffer_size: 6
      hard_from_softs: false
      num_hard_samples: 4
      num_samples: 25
      buffer_replace_prob: 0.25
      buffer_replay_prob: 0.9

    # The flow model arguments
    layers: [10, 10, 10]
    populate_features: True
    num_transforms: 1
    additive: False
    residual: False
    bias: true
    activation: torch.nn.LeakyReLU
    activation_args:
      negative_slope: 0.1
    scale_transform: true
    scale_transform_args:
      post_act_scale: 2.5
  
  # the optimizer
  optimizer: [torch.optim.AdamW, torch.optim.AdamW]
  optimizer_args:
  - weight_decay: 0.25
  - weight_decay: 0.1   
  optimizer_parameters:
    - model.flow
    - model.permutation_model
  optimizer_is_active: 
    - > 
      lambda training_module: training_module.current_phase == 'maximization' if hasattr(training_module, 'current_phase') else True
    - >
      lambda training_module: training_module.current_phase == 'expectation' if hasattr(training_module, 'current_phase') else True
  grad_clip_val: 1.0
  lr: [0.01, 0.01]
  scheduler: 
    - ocd.training.schedulers.reduce_on_increase.ReduceLROnIncrease
    - ocd.training.schedulers.reduce_on_increase.ReduceLROnIncrease
  scheduler_args:
    - mode: min
      factor: 0.5
      patience: 500
      min_lr: 0.000005
      threshold: 0.0001
    - mode: min
      factor: 0.5
      patience: 500
      min_lr: 0.000005
      threshold: 0.0001
  scheduler_name: ["lr_scheduler_maximization", "lr_scheduler_expectation"]
  scheduler_optimizer: [0, 1]
  scheduler_interval: ["epoch", "epoch"]
  # # # # # scheduler_frequency: [22500, 22500]
  scheduler_monitor: ["loss", "loss"]
  # the loss
  # objective_cls: ocd.training.terms.NLLTerm 
  objective_args:
    nll:
      code: >
        def func(training_module, batch):
          t = training_module.forward(batch)
          res = t['log_prob']
          return -res.mean()
      function_of_interest: func