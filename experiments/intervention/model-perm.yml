class_path: lightning_toolbox.TrainingModule
init_args:
  # the model
  model_cls: ocd.models.ocdaf.OCDAF
  model_args:
    # Permutation learner arguments
    use_permutation: True
    permutation_learner_args:
      permutation_type: hybrid-sparse-map-simulator
    # Base distribution arguments
    base_distribution: torch.distributions.Normal
    base_distribution_args:
      loc: 0.0
      scale: 1.0
    # The flow model arguments
    layers: [25, 25, 25]
    populate_features: True
    num_transforms: 1
    additive: False
    residual: False
    bias: true
    activation: torch.nn.LeakyReLU
    activation_args:
      negative_slope: 0.1

  # the optimizer
  optimizer: torch.optim.Adam
  # optimizer_args:
  # weight_decay: 0.25
  optimizer_parameters: model.flow

  lr: 0.01
  scheduler: ocd.training.schedulers.reduce_on_increase.ReduceLROnIncrease
  scheduler_args:
    mode: min
    factor: 0.5
    patience: 100
    min_lr: 0.00001
    threshold: 0.001
  scheduler_name: ["lr_scheduler_maximization"]
  scheduler_interval: "step"
  scheduler_monitor: ["loss/train"]
  # the loss
  # objective_cls: ocd.training.terms.NLLTerm
  objective_args:
    nll:
      code: >
        def func(training_module, batch):
          t = training_module.forward(batch)
          res = t['log_prob']
          return -res.mean()
      function_of_interest: func
