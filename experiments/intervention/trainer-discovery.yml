callbacks:
  - class_path: ocd.training.callbacks.checkpointing.DebuggedModelCheckpoint
    init_args:
      dirpath: experiments/intervention/discovery/checkpoints/3
      verbose: true
      save_top_k: -1 # save all models
      every_n_epochs: 1 # save on phase change
  # - class_path: ocd.training.callbacks.data_visualizer.DataVisualizer
  - class_path: lightning.pytorch.callbacks.LearningRateMonitor
    init_args:
      logging_interval: epoch
  - class_path: ocd.training.callbacks.qqplot.QQplotCallback
    init_args:
      every_n_epochs: 100
      num_samples: 1000
      bins: 200
  - class_path: ocd.training.callbacks.intervention.InterventionCallback
    init_args:
      every_n_epochs: 100
      k: 7.5
      num_samples: 100
      num_interventions: 500
  # Phase changer
  - class_path: ocd.training.callbacks.phase_changer.PhaseChangerCallback
    init_args:
      starting_phase: maximization
      # The settings regarding epoch limit values
      maximization_epoch_limit: 120
      expectation_epoch_limit: 50
      # The settings regarding the generalization gap
      patience: 25
      threshold: 0.0001
      cooldown: 120
      reset_optimizers: False
      reinitialize_weights_on_maximization: False
  # Permutation results
  - class_path: ocd.training.callbacks.intervention_discovery.PermutationEvaluationCallback
    init_args:
      every_n_epochs: 25
accelerator: gpu
devices: 1
num_nodes: 0
max_epochs: 3000
log_every_n_steps: 1
check_val_every_n_epoch: 1
enable_checkpointing: true
enable_model_summary: true
enable_progress_bar: false
logger:
  class_path: lightning.pytorch.loggers.WandbLogger
  init_args:
    project: interventions-v7
    name: chain-3-discovery
