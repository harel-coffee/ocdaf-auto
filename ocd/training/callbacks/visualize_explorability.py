"""
This file contains a callback that visualizes the explorability of the model.

The explorability of the model is a concept based on the distribution of permutations that 
are generated by the model at each phase.

We expect the model starting off exploring a lot of permutations and then ends up concentrating
on a key set of permutations that resemble a correct ordering. To do that, we use a visualization
of the permutation matrices using the doubly stochastic Birkhoff polytope.

In the beginning we will train a PCA on the Birkhoff polytope of some size, and then, after 
each phase change we will get all the logged permutations of that phase, feed it to the pre-trained
PCA and do a scatter plot to show the distribution of the permutations in that phase.
"""

import lightning.pytorch as pl
from lightning.pytorch.callbacks import Callback
import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from ocd.models.permutation.utils import sinkhorn
import torch


class ExplorabilityCallback(Callback):
    def __init__(
        self,
        permutation_size: int,
        seed=None,
        n_sample=200,
        log_on_phase_change: bool = True,
        log_every_n_epochs: int = 0,
        fit_every_time: bool = False,
    ) -> None:
        self.permutation_size = permutation_size
        self.last_saved_phase = None

        self.log_on_phase_change = log_on_phase_change
        self.log_every_n_epochs = log_every_n_epochs
        self.log_every_n_epochs_counter = 0
        self.fit_every_time = fit_every_time
        self.pca = PCA(n_components=2)

        self.seed = seed

        if not self.fit_every_time:
            # sample n_sample x permutation_size x permutation_size gumbel noises
            gumbel_noise = np.random.gumbel(size=(n_sample, permutation_size, permutation_size))
            # turn the gumbel noise into a torch tensor
            gumbel_noise = torch.from_numpy(gumbel_noise).float()
            polytope = (
                sinkhorn(torch.cat([gumbel_noise, gumbel_noise / 0.1, gumbel_noise / 0.05], dim=0), 100)
                .detach()
                .numpy()
            )

            # train a PCA on all the elements of the polytope
            self.pca.fit(polytope.reshape(-1, permutation_size * permutation_size))
            self.polytope = self.pca.transform(polytope.reshape(-1, permutation_size * permutation_size))

    def print_unique_permutations(self, logged_permutations):
        real_logged_permutations = logged_permutations.argmax(axis=-1)
        # get the unique rows and the number of times they appear
        unique_rows, counts = np.unique(real_logged_permutations, axis=0, return_counts=True)
        print("Permutations that were seen:")
        for row, count in zip(unique_rows, counts):
            print(row, " : ", count, " times")

    def check_should_log(self, pl_module: pl.LightningModule) -> bool:
        # If the logging is not at the end of the phase change then
        # check frequency and return accordingly
        if not self.log_on_phase_change:
            t = self.log_every_n_epochs_counter
            self.log_every_n_epochs_counter = (t + 1) % self.log_every_n_epochs
            return t == self.log_every_n_epochs - 1

        # If the last phase is the same as the current phase, do nothing
        # This indicates no phase change edge
        if pl_module.get_phase() == self.last_saved_phase:
            return False
        # Do nothing if the last phase was None
        # (This means this is the first time that it is being called)
        if self.last_saved_phase is None:
            self.last_saved_phase = pl_module.get_phase()
            return False
        # A phase change has happened and now is the time to visualize the explorability
        self.last_saved_phase = pl_module.get_phase()
        return True

    def on_train_epoch_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule) -> None:
        ret = super().on_train_epoch_end(trainer, pl_module)

        # Get all the logged permutations of that epoch and clear the log
        # (this is a percaution to make sure memory is not filled up)

        logged_permutations = pl_module.model.get_logged_permutations().numpy()

        permutation_without_noise = pl_module.model.permutation_model.soft_permutation()
        permutation_without_noise = permutation_without_noise.detach().numpy()

        # concatenate the logged permutations with the permutation without noise
        logged_permutations = np.concatenate((logged_permutations, permutation_without_noise), axis=0)

        pl_module.model.clear_logged_permutations()

        if not self.check_should_log(pl_module):
            return ret

        # transform the logged permutations using the PCA
        if self.fit_every_time:
            self.pca.fit(logged_permutations.reshape(-1, self.permutation_size * self.permutation_size))

        transformed_permutations = self.pca.transform(
            logged_permutations.reshape(-1, self.permutation_size * self.permutation_size)
        )

        # get the root tensorboard logger
        logger = pl_module.logger.experiment

        # plot the permutation using matplotlib and save it to a numpy array
        fig, ax = plt.subplots()

        try:
            ax.set_title("Birkhoff Polytope of Permutations")
            ax.set_ylabel(f"phase {pl_module.get_phase()}")
            ax.set_xlabel(f"epoch: {pl_module.current_epoch}")
            if not self.fit_every_time:
                ax.scatter(self.polytope[:, 0], self.polytope[:, 1], s=1, c="green", label="Polytope boundaries")
            ax.scatter(
                transformed_permutations[:-1, 0], transformed_permutations[:-1, 1], s=1, label="Sampled permutations"
            )
            ax.scatter(
                transformed_permutations[-1:, 0],
                transformed_permutations[-1:, 1],
                s=20,
                c="red",
                label="Gamma without noise",
            )
            ax.legend()

            fig.canvas.draw()
            # convert the figure to a numpy array
            data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep="")
            data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))
            # log the figure to tensorboard
            logger.add_image(f"explorability/all_perm_mat", data, pl_module.current_epoch, dataformats="HWC")
        finally:
            plt.close()

        return ret
